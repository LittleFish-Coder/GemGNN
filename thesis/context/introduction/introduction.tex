% ------------------------------------------------
\StartChapter{Introduction}{chapter:introduction}
% ------------------------------------------------

\section{Research Background and Motivation}

In the digital age, the proliferation of fake news has emerged as one of the most pressing challenges threatening information integrity and democratic discourse. According to Vosoughi et al. \cite{vosoughi2018spread}, false news spreads six times faster than true news on social media platforms, reaching more people and penetrating deeper into social networks. This phenomenon has far-reaching consequences, from influencing electoral outcomes to undermining public health responses during critical events such as the COVID-19 pandemic.

Traditional approaches to fake news detection have relied heavily on two primary paradigms: content-based analysis and propagation-based modeling~\cite{zhou2020survey}. Content-based methods analyze linguistic features, semantic patterns, and textual inconsistencies within news articles, while propagation-based approaches examine how information spreads through social networks by modeling user interactions, sharing patterns, and network topology. However, both paradigms face significant limitations in real-world deployment scenarios.

The most critical challenge in contemporary fake news detection is the few-shot learning problem~\cite{wang2020fewshot}, where detection systems must accurately classify news articles with minimal labeled training data. This scenario is particularly common when dealing with emerging topics, breaking news events, or novel misinformation campaigns where extensive labeled datasets are not readily available. Traditional deep learning approaches, which typically require thousands of labeled examples per class, fail to perform adequately in such data-scarce environments.

Furthermore, existing propagation-based methods~\cite{shu2017fake}, while often achieving high performance, suffer from fundamental practical limitations. These approaches require access to comprehensive user interaction data, including social network structures, user profiles, and temporal propagation patterns. Such data is increasingly difficult to obtain due to privacy regulations, platform restrictions, and the real-time nature of misinformation spread. Additionally, these methods are vulnerable to sophisticated adversarial attacks where malicious actors can manipulate propagation patterns to evade detection.

\section{Research Contributions}

This thesis presents GemGNN (Generative Multi-view Interaction Graph Neural Networks), a novel framework that addresses the challenges of few-shot fake news detection through several key innovations that collectively establish a new paradigm for content-based fake news detection:

% TODO: Add Table X - Summary of key contributions and their impact on addressing existing limitations

\textbf{Generative User Interaction Simulation:} We introduce the first systematic approach to synthesize realistic user interactions using Large Language Models (LLMs), creating a heterogeneous graph structure that captures both content and social context without requiring real user propagation data. Our method leverages LLMs to generate diverse user responses with multiple semantic tones (neutral, affirmative, skeptical), effectively creating synthetic social signals that enhance content-based detection while maintaining privacy protection. This innovation represents a paradigm shift from dependency on real social data to controllable synthetic interaction generation.

% Comment: This addresses the fundamental limitation of requiring user behavior data while maintaining the benefits of social context modeling

\textbf{Adaptive Graph Construction Methodology:} We develop a comprehensive dual approach to graph edge construction that encompasses both traditional KNN and test-isolated KNN strategies, each optimized for different deployment scenarios and evaluation objectives. Our framework provides principled guidance for selecting between approaches based on specific application requirements: traditional KNN for performance-critical batch processing scenarios, and test-isolated KNN for methodologically rigorous evaluation and streaming deployment conditions. This contribution establishes the first systematic analysis of the performance vs. evaluation realism trade-offs in graph-based few-shot learning.

\textbf{DeBERTa-Enhanced Multi-View Graph Architecture:} We propose a multi-view learning framework that leverages DeBERTa's disentangled attention architecture to create superior embedding partitions for capturing diverse semantic perspectives. Unlike conventional approaches, our method exploits DeBERTa's structured representation organization to partition embeddings into coherent semantic subspaces that retain discriminative power while emphasizing different linguistic aspects. Each view constructs its own similarity-based graph, enabling the model to learn from multiple semantic perspectives simultaneously while maintaining semantic consistency across partitions.

% Comment: Multi-view learning provides implicit regularization and richer representation learning in few-shot scenarios

\textbf{Enhanced Heterogeneous Graph Neural Networks:} We design a specialized Heterogeneous Graph Attention Network (HAN) architecture that effectively models complex type-specific relationships between news articles and generated user interactions. Our architecture employs hierarchical attention mechanisms to learn both node-level importance within each relationship type and semantic-level importance across different relationship types. The framework enables effective transductive learning by leveraging both labeled and unlabeled nodes during message passing while restricting loss computation to labeled nodes only.

\textbf{Optimized Training Strategy:} Through extensive empirical evaluation, we demonstrate that standard cross-entropy loss achieves optimal performance for few-shot fake news detection, eliminating the need for complex loss combinations. Our training strategy incorporates validation loss thresholding (stopping when validation loss < 0.3) alongside patience-based early stopping to ensure robust model convergence without overfitting.

\textbf{Comprehensive Few-Shot Evaluation Framework:} We establish rigorous experimental protocols that include extensive parameter grid searches across 2,688 different configurations, systematic ablation studies, and comparison with diverse baseline approaches ranging from traditional machine learning to large language models. Our evaluation ensures fair comparison with existing methods while maintaining realistic few-shot learning constraints and preventing common sources of evaluation bias.

% TODO: Add Figure X - Overview of GemGNN contributions and how they address existing limitations

\textbf{Methodological Innovations:} Beyond individual components, our work introduces several methodological innovations: (1) systematic integration of generative AI with graph neural networks for fake news detection, (2) rigorous few-shot evaluation protocols that prevent information leakage, (3) comprehensive analysis of heterogeneous graph architectures in few-shot scenarios, (4) novel approaches to synthetic data generation that enhance rather than replace human-labeled training data, and (5) empirical validation that simple cross-entropy loss achieves optimal performance, challenging conventional wisdom about the necessity of complex loss formulations in few-shot learning scenarios.

The combination of these contributions enables GemGNN to achieve superior performance in few-shot fake news detection while maintaining practical applicability in privacy-constrained and socially-limited deployment scenarios. Our approach establishes new state-of-the-art results across multiple datasets and few-shot configurations while providing a foundation for future research in synthetic data generation and heterogeneous graph modeling for misinformation detection.

\section{Thesis Organization}

The remainder of this thesis is organized as follows:

\textbf{Chapter 2: Problem Statement} formally defines the few-shot fake news detection problem addressed in this thesis and establishes the mathematical notation used throughout our methodology. We present the fundamental challenges that motivate our research and provide a rigorous problem formulation with key constraints and evaluation metrics.

\textbf{Chapter 3: Related Work} provides a comprehensive review of existing fake news detection methods, including traditional feature-engineering approaches, deep learning techniques, few-shot learning strategies in NLP, graph neural networks for text classification, and graph-based fake news detection methods. We analyze the limitations of current approaches and position our work within the broader research landscape.

\textbf{Chapter 4: Methodology} presents the complete GemGNN framework, detailing the generative user interaction simulation, adaptive graph construction methodology (KNN vs test-isolated KNN), DeBERTa encoder selection rationale, multi-view graph architecture, and the heterogeneous graph neural network design. We provide comprehensive algorithmic descriptions and theoretical justifications for each component, along with decision frameworks for practitioners.

\textbf{Chapter 5: Experimental Setup} describes our experimental methodology, including dataset preprocessing, baseline method implementations, evaluation protocols, and hyperparameter configurations. We ensure reproducibility and fair comparison across all experimental conditions.

\textbf{Chapter 6: Results and Analysis} presents comprehensive experimental results, including main performance comparisons, ablation studies, and detailed analysis of model behavior. We provide insights into why our approach succeeds in few-shot scenarios and identify the key factors contributing to performance improvements.

\textbf{Chapter 7: Conclusion and Future Work} summarizes our contributions, discusses the implications of our findings, acknowledges current limitations, and outlines promising directions for future research in few-shot fake news detection.

% ------------------------------------------------
\EndChapter
% ------------------------------------------------
