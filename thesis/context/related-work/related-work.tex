% ------------------------------------------------
\StartChapter{Related Work}{chapter:related-work}
% ------------------------------------------------

This chapter reviews existing approaches to fake news detection, with emphasis on methods relevant to few-shot learning scenarios. We organize the literature according to the evolution of detection paradigms and identify key limitations that motivate our research.

\section{Few-Shot Learning Fundamentals}

\textbf{Definition:} Few-shot learning is a machine learning paradigm where models learn to make accurate predictions with minimal labeled training data. Formally, given a support set $\mathcal{S} = \{(x_i, y_i)\}_{i=1}^{K \times N}$ containing $K$ labeled examples for each of $N$ classes, the objective is to learn a classifier that can accurately predict labels for a query set with limited supervision.

\textbf{Core Challenges:} Few-shot learning presents fundamental challenges that differentiate it from conventional machine learning: (1) \emph{Limited training data} leads to high variance and overfitting, (2) \emph{Domain shift} where models trained on few examples fail to generalize to new patterns, and (3) \emph{Evaluation challenges} requiring careful experimental design to prevent information leakage.

In fake news detection, few-shot scenarios are particularly relevant because: (1) emerging misinformation patterns have limited labeled examples, (2) manual labeling is expensive and time-consuming, and (3) rapid response is needed for new threats before sufficient training data accumulates.

\section{Traditional Machine Learning Approaches}

Early computational approaches to fake news detection relied on hand-crafted features and traditional machine learning algorithms.

\textbf{Feature Engineering Methods:} The earliest approaches employed Term Frequency-Inverse Document Frequency (TF-IDF) representations combined with Multi-Layer Perceptrons (MLPs) or Support Vector Machines \cite{perez2017automatic, wang2017liar}. These methods extract bag-of-words features and learn linear or shallow non-linear mappings to classify news authenticity.

More sophisticated approaches incorporated linguistic features such as sentiment analysis, readability scores, lexical diversity measures, and syntactic complexity \cite{horne2017just, rashkin2017truth}. These methods hypothesize that fake news exhibits distinct linguistic patterns, such as more emotional language or simpler sentence structures.

\textbf{Limitations:} Traditional approaches suffer from critical limitations: (1) they ignore contextual relationships and word order, (2) they cannot capture semantic similarity between different expressions of similar concepts, (3) they fail to model discourse-level patterns characteristic of misinformation, and (4) they perform poorly in few-shot scenarios due to sparse feature representations.

\section{Deep Learning Approaches}

The advent of deep learning revolutionized fake news detection by enabling sophisticated semantic analysis, though most methods struggle in few-shot scenarios.

\subsection{Transformer-based Models}

\textbf{BERT and Variants:} The introduction of BERT (Bidirectional Encoder Representations from Transformers) and its variants like RoBERTa marked significant advancement in content-based detection \cite{devlin2018bert, liu2019roberta, kaliyar2021fakebert}. These models provide rich contextual representations that capture bidirectional dependencies and complex semantic relationships.

BERT-based approaches typically fine-tune pre-trained language models on fake news classification tasks, achieving strong performance on standard benchmarks. However, they face significant challenges in few-shot scenarios: (1) they require substantial task-specific fine-tuning data, (2) they are prone to overfitting when labeled data is scarce, and (3) they treat each document independently, missing systematic patterns across related articles.

\subsection{Large Language Models}

\textbf{In-Context Learning Approaches:} Recent work explores using large language models such as GPT-4, LLaMA, and Gemma for fake news detection through in-context learning \cite{touvron2023llama, team2024gemma}. These approaches provide few examples within the prompt and ask the model to classify new instances.

\textbf{Performance Limitations:} Despite impressive general language understanding capabilities, LLMs demonstrate surprisingly poor performance on fake news detection in few-shot scenarios. Key limitations include: (1) inconsistent prompt sensitivity where performance varies dramatically based on prompt formulation, (2) surface-level pattern reliance focusing on obvious linguistic markers rather than sophisticated misinformation patterns, (3) lack of systematic verification capabilities for factual claims, and (4) potential data contamination concerns where models may have seen test instances during training.

Recent systematic evaluations show that LLMs consistently underperform specialized approaches in few-shot scenarios, often struggling to achieve accuracy above 65\% \cite{huang2023chatgpt, zhang2023can}.

\section{Graph-based Approaches}

Graph-based methods represent a paradigm shift by modeling relationships between entities in the misinformation ecosystem, though they reveal critical limitations in few-shot contexts.

\subsection{Document-level Graph Methods}

\textbf{Text-GCN and Variants:} Text Graph Convolutional Networks construct graphs where documents and words are nodes, with edges indicating document-word relationships and word co-occurrence patterns \cite{yao2019graph}. More recent BertGCN approaches combine BERT embeddings with graph convolutional networks to leverage both semantic representations and structural information \cite{lin2021bertgcn}.

While these approaches effectively leverage graph structure, they face fundamental challenges in few-shot scenarios: (1) document-word graphs require substantial vocabulary coverage problematic with few labeled documents, (2) word co-occurrence patterns become unreliable with limited training data, and (3) semantic similarity graphs become less reliable when based on limited examples.

\textbf{BREAK - Sequential Graph Modeling:} BREAK (Broad-Range Semantic Modeling) represents advancement in combining graph neural networks with sequential processing \cite{ji2023break}. The method constructs heterogeneous graphs incorporating multiple entity types while applying sequence modeling to capture temporal dynamics and textual patterns.

BREAK demonstrates strong performance by effectively leveraging both structural and sequential information. However, it faces limitations in few-shot scenarios: (1) the dual-stream architecture requires substantial training data to learn coordination between graph and sequence processing, (2) partial reliance on user interaction data, and (3) complexity makes it prone to overfitting with scarce labeled examples.

\subsection{User Propagation-based Methods}

Many state-of-the-art systems model misinformation spread through social networks by analyzing user sharing patterns and network topology \cite{shu2017fake, zhou2020survey}. These methods often achieve high performance by exploiting differential propagation patterns between fake and real news.

However, propagation-based approaches have fundamental limitations: (1) they require extensive user behavior data often unavailable due to privacy constraints, (2) they are vulnerable to adversarial manipulation, and (3) they cannot handle breaking news scenarios where propagation patterns have not developed.

\textbf{Less4FD - Few-Shot Entity-Aware Detection:} Less4FD specifically addresses few-shot learning through a meta-learning framework incorporating entity awareness \cite{zhang2023less4fd}. The approach constructs heterogeneous graphs using primarily content-based features with minimal social signals, making it applicable in privacy-constrained scenarios.

The core innovation lies in entity-aware graph construction where named entities serve as bridge nodes connecting semantically related content. This enables capturing relationships beyond simple text similarity, particularly important for detecting misinformation involving factual manipulation.

Less4FD employs two-phase training: (1) self-supervised pre-training learning general entity relationship patterns from unlabeled data, and (2) meta-learning fine-tuning adapting to specific tasks with few examples. While representing significant progress, limitations remain: (1) entity extraction quality heavily influences performance, (2) meta-learning requires substantial computational resources, and (3) evaluation protocols do not always ensure proper test isolation.

\section{Limitations of Existing Methods}

Our comprehensive review reveals fundamental limitations that motivate our research:

\textbf{Social Data Dependency:} Most high-performing systems rely on user interaction patterns or social network structures, severely limiting applicability where such data is unavailable due to privacy constraints or platform restrictions.

\textbf{Poor Few-Shot Performance:} Traditional deep learning approaches, including state-of-the-art transformer models, suffer significant performance degradation in few-shot scenarios due to overfitting and limited generalization.

\textbf{Information Leakage in Evaluation:} Many approaches employ unrealistic evaluation protocols allowing information sharing between test instances, leading to overly optimistic performance estimates that do not reflect deployment conditions.

\textbf{Limited Structural Modeling:} Content-based approaches treat documents independently, missing important structural relationships between related articles that could provide valuable detection signals.

These limitations highlight the need for approaches that achieve strong few-shot performance while maintaining realistic evaluation protocols and avoiding dependency on user behavior data. Our GemGNN framework directly addresses these challenges through content-based heterogeneous graph neural networks enhanced with synthetic interaction generation and rigorous test isolation protocols.

% ------------------------------------------------
\EndChapter
% ------------------------------------------------
