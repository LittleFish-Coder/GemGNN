% ------------------------------------------------
\StartChapter{Related Work}{chapter:related-work}
% ------------------------------------------------

This chapter reviews existing approaches to fake news detection, with emphasis on methods relevant to few-shot learning scenarios. We organize the literature according to the evolution of detection paradigms and identify key limitations that motivate our research.

\section{Few-Shot Learning Fundamentals}

\textbf{Definition:} Few-shot learning is a machine learning paradigm where models learn to make accurate predictions with minimal labeled training data. Formally, given a support set $\mathcal{S} = \{(x_i, y_i)\}_{i=1}^{K \times N}$ containing $K$ labeled examples for each of $N$ classes, the objective is to learn a classifier that can accurately predict labels for a query set with limited supervision.

\textbf{Core Challenges:} Few-shot learning presents fundamental challenges that differentiate it from conventional machine learning: (1) \emph{Limited training data} leads to high variance and overfitting, (2) \emph{Domain shift} where models trained on few examples fail to generalize to new patterns, and (3) \emph{Evaluation challenges} requiring careful experimental design to prevent information leakage.

In fake news detection, few-shot scenarios are particularly relevant because: (1) emerging misinformation patterns have limited labeled examples, (2) manual labeling is expensive and time-consuming, and (3) rapid response is needed for new threats before sufficient training data accumulates.

\section{Traditional Machine Learning Approaches}

Early computational approaches to fake news detection relied on hand-crafted features and traditional machine learning algorithms.

\textbf{Feature Engineering Methods:} The earliest approaches employed Term Frequency-Inverse Document Frequency (TF-IDF) representations combined with Multi-Layer Perceptrons (MLPs) or Support Vector Machines \cite{perez2017automatic, wang2017liar}. These methods extract bag-of-words features and learn linear or shallow non-linear mappings to classify news authenticity.

More sophisticated approaches incorporated linguistic features such as sentiment analysis, readability scores, lexical diversity measures, and syntactic complexity \cite{horne2017just, rashkin2017truth}. These methods hypothesize that fake news exhibits distinct linguistic patterns, such as more emotional language or simpler sentence structures.

\textbf{Limitations:} Traditional approaches suffer from critical limitations: (1) they ignore contextual relationships and word order, (2) they cannot capture semantic similarity between different expressions of similar concepts, (3) they fail to model discourse-level patterns characteristic of misinformation, and (4) they perform poorly in few-shot scenarios due to sparse feature representations.

\section{Deep Learning Approaches}

The advent of deep learning revolutionized fake news detection by enabling sophisticated semantic analysis, though most methods struggle in few-shot scenarios.

\subsection{Transformer-based Models}

\textbf{BERT and Variants:} The introduction of BERT (Bidirectional Encoder Representations from Transformers) and its variants like RoBERTa marked significant advancement in content-based detection \cite{devlin2018bert, liu2019roberta, kaliyar2021fakebert}. These models provide rich contextual representations that capture bidirectional dependencies and complex semantic relationships.

BERT-based approaches typically fine-tune pre-trained language models on fake news classification tasks, achieving strong performance on standard benchmarks. However, they face significant challenges in few-shot scenarios: (1) they require substantial task-specific fine-tuning data, (2) they are prone to overfitting when labeled data is scarce, and (3) they treat each document independently, missing systematic patterns across related articles.

\subsection{Large Language Models}

\textbf{In-Context Learning Approaches:} Recent work explores using large language models such as GPT-4, LLaMA, and Gemma for fake news detection through in-context learning \cite{touvron2023llama, team2024gemma}. These approaches provide few examples within the prompt and ask the model to classify new instances.

\textbf{Performance Limitations:} Despite impressive general language understanding capabilities, LLMs demonstrate surprisingly poor performance on fake news detection in few-shot scenarios. Key limitations include: (1) inconsistent prompt sensitivity where performance varies dramatically based on prompt formulation, (2) surface-level pattern reliance focusing on obvious linguistic markers rather than sophisticated misinformation patterns, (3) lack of systematic verification capabilities for factual claims, and (4) potential data contamination concerns where models may have seen test instances during training.

Recent systematic evaluations show that LLMs consistently underperform specialized approaches in few-shot scenarios, often struggling to achieve accuracy above 65\% \cite{huang2023chatgpt, zhang2023can}.

\section{Graph-based Approaches}

Graph-based methods represent a paradigm shift by modeling relationships between entities in the misinformation ecosystem. These approaches can be categorized based on their learning paradigm and the type of graph-level predictions they make.

\subsection{Graph Classification Methods}

\textbf{BREAK - Graph with Sequence Modeling:} BREAK (Broad-Range Semantic Modeling for Fake News Detection) represents a graph classification approach that treats each news article and its associated social context as a complete graph structure \cite{ji2023break}. The method constructs heterogeneous graphs incorporating multiple entity types (news content, users, topics) and applies dual-stream processing combining graph neural networks with sequential modeling to capture both structural relationships and temporal dynamics.

BREAK's innovation lies in treating fake news detection as a graph-level classification task where the entire social context graph is classified as containing real or fake news. The dual-stream architecture processes graph structure through GNNs while simultaneously modeling sequential patterns in textual content, enabling comprehensive analysis of both relational and temporal signals.

However, BREAK faces significant limitations in few-shot scenarios: (1) the dual-stream architecture requires substantial training data to learn effective coordination between graph and sequence processing components, (2) graph classification requires diverse graph structures that may not be available with limited training examples, and (3) the complex architecture is prone to overfitting when training data is scarce.

\subsection{Node Classification Methods without Social Propagation}

\textbf{Less4FD - Entity-Aware Content-Based Detection:} Less4FD addresses few-shot fake news detection through entity-aware heterogeneous graph construction that focuses purely on content-based relationships without relying on social propagation patterns \cite{zhang2023less4fd}. The method treats fake news detection as a node classification task where individual news articles (nodes) are classified based on their content and entity relationships.

The core innovation lies in entity-aware graph construction where named entities serve as bridge nodes connecting semantically related news content. This approach constructs graphs using content similarity and entity co-occurrence patterns, enabling the model to capture relationships beyond simple text similarity. The method is particularly valuable for detecting misinformation involving factual manipulation where entity relationships provide crucial signals.

Less4FD employs a meta-learning framework with two-phase training: (1) self-supervised pre-training on entity relationship patterns from unlabeled data, and (2) meta-learning fine-tuning for few-shot adaptation. The approach demonstrates that effective fake news detection can be achieved without social propagation data, making it applicable in privacy-constrained scenarios where user behavior data is unavailable.

Limitations include: (1) heavy dependence on entity extraction quality, which can significantly impact performance, (2) computational overhead of meta-learning components, and (3) potential for overfitting in extremely low-resource scenarios despite few-shot design.

\subsection{Node Classification Methods with Social Propagation}

\textbf{DECOR and Propagation-Based Approaches:} Traditional propagation-based methods model misinformation spread through social networks by analyzing user sharing patterns and network topology \cite{shu2017fake, zhou2020survey}. These approaches treat fake news detection as node classification where individual news articles are classified based on how they propagate through social networks.

DECOR and similar methods leverage the observation that fake and real news exhibit different propagation patterns in social networks. They construct graphs where news articles and users are nodes, with edges representing sharing, commenting, or other interaction behaviors. The classification is performed at the news node level, using propagation features derived from the social network structure.

These propagation-based approaches often achieve high performance by exploiting differential spreading patterns, user credibility signals, and temporal dynamics of information flow. However, they have fundamental limitations: (1) they require extensive user behavior data often unavailable due to privacy constraints, (2) they are vulnerable to adversarial manipulation where malicious actors can artificially create propagation patterns, and (3) they cannot handle breaking news scenarios where propagation patterns have not yet developed.

\subsection{Document-Level Graph Methods}

\textbf{Text-GCN and Variants:} Text Graph Convolutional Networks construct graphs where documents and words are nodes, with edges indicating document-word relationships and word co-occurrence patterns \cite{yao2019graph}. More recent BertGCN approaches combine BERT embeddings with graph convolutional networks to leverage both semantic representations and structural information \cite{lin2021bertgcn}.

While these approaches effectively leverage graph structure for document classification, they face fundamental challenges in few-shot scenarios: (1) document-word graphs require substantial vocabulary coverage problematic with few labeled documents, (2) word co-occurrence patterns become unreliable with limited training data, and (3) semantic similarity graphs become less reliable when based on limited examples.

\section{Limitations of Existing Methods}

Our comprehensive review reveals fundamental limitations that motivate our research:

\textbf{Social Data Dependency:} Most high-performing systems rely on user interaction patterns or social network structures, severely limiting applicability where such data is unavailable due to privacy constraints or platform restrictions.

\textbf{Poor Few-Shot Performance:} Traditional deep learning approaches, including state-of-the-art transformer models, suffer significant performance degradation in few-shot scenarios due to overfitting and limited generalization.

\textbf{Information Leakage in Evaluation:} Many approaches employ unrealistic evaluation protocols allowing information sharing between test instances, leading to overly optimistic performance estimates that do not reflect deployment conditions.

\textbf{Limited Structural Modeling:} Content-based approaches treat documents independently, missing important structural relationships between related articles that could provide valuable detection signals.

These limitations highlight the need for approaches that achieve strong few-shot performance while maintaining realistic evaluation protocols and avoiding dependency on user behavior data. Our GemGNN framework directly addresses these challenges through content-based heterogeneous graph neural networks enhanced with synthetic interaction generation and rigorous test isolation protocols.

% ------------------------------------------------
\EndChapter
% ------------------------------------------------
