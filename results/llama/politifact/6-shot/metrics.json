{
  "accuracy": 0.8333333333333334,
  "f1": 0.8196684284230022,
  "precision": 0.8333333333333334,
  "recall": 0.8333333333333334,
  "num_samples": 102,
  "num_generation_errors": 0,
  "run_info": {
    "model_type": "llama",
    "model_hf_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "dataset_name": "politifact",
    "k_shot": 6,
    "internal_seed": 42,
    "max_new_tokens": 10,
    "batch_size": 4,
    "max_example_length": 500,
    "effective_device_type": "cuda",
    "execution_time_seconds": 95.2154631614685
  },
  "macro_precision": 0.8333333333333334,
  "macro_recall": 0.738072744449693,
  "macro_f1_score": 0.7650088087816778,
  "confusion_matrix": [
    [
      70,
      3
    ],
    [
      14,
      15
    ]
  ],
  "calculation_info": "Metrics (re)calculated from predictions.json by calculate_and_update_metrics.py"
}