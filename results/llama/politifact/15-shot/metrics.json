{
  "accuracy": 0.8137254901960784,
  "f1": 0.7899131341110762,
  "precision": 0.8211261777438247,
  "recall": 0.8137254901960784,
  "num_samples": 102,
  "num_generation_errors": 0,
  "run_info": {
    "model_type": "llama",
    "model_hf_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "dataset_name": "politifact",
    "k_shot": 15,
    "internal_seed": 42,
    "max_new_tokens": 10,
    "batch_size": 4,
    "max_example_length": 500,
    "effective_device_type": "cuda",
    "execution_time_seconds": 133.96525263786316
  },
  "macro_precision": 0.8319805194805194,
  "macro_recall": 0.6931979215871517,
  "macro_f1_score": 0.7200635562617362,
  "confusion_matrix": [
    [
      71,
      2
    ],
    [
      17,
      12
    ]
  ],
  "calculation_info": "Metrics (re)calculated from predictions.json by calculate_and_update_metrics.py"
}