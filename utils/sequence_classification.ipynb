{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification\n",
    "- ref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "- dataset: [LittleFish-Coder/Fake_News_KDD2020](https://huggingface.co/datasets/LittleFish-Coder/Fake_News_KDD2020)\n",
    "- pretrained model: [distilbert/distilbert-base-uncased](https://huggingface.co/distilbert/distilbert-base-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "use the [`LittleFish-Coder/Fake_News_KDD2020`](https://huggingface.co/datasets/LittleFish-Coder/Fake_News_KDD2020) dataset from huggingface datasets library\n",
    "\n",
    "- 0: real news\n",
    "- 1: fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4487/4487 [00:00<00:00, 35360.95 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 37046.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset: DatasetDict = load_dataset(\"LittleFish-Coder/Fake_News_KDD2020\", download_mode=\"reuse_cache_if_exists\", cache_dir=\"dataset\")   # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'embeddings', 'label'],\n",
      "        num_rows: 4487\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'embeddings', 'label'],\n",
      "        num_rows: 499\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print(f\"Dataset: {dataset}\")\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training sample\n",
      "Keys: dict_keys(['text', 'embeddings', 'label'])\n",
      "Text: Oops. Something went wrong. Please try again later  Looks like we are having a problem on the server.\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# quick look at the data\n",
    "first_train = train_dataset[0]\n",
    "print(f\"First training sample\")\n",
    "print(f\"Keys: {first_train.keys()}\")\n",
    "print(f\"Text: {first_train['text']}\")\n",
    "print(f\"Label: {first_train['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (Tokenize)\n",
    "The next step is to load a [`DistilBERT`](https://huggingface.co/distilbert/distilbert-base-uncased) tokenizer to preprocess the `text` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERTâ€™s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use Datasets map function. \n",
    "\n",
    "You can speed up map by setting `batched=True` to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4487/4487 [00:02<00:00, 1896.61 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 1676.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, the dataset will contain the original text and the following attributes that DistilBERT uses as input:\n",
    "\n",
    "- `input_ids`: The token indices in the vocabulary\n",
    "- `attention_mask`: Which parts of the sequence DistilBERT should pay attention to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First tokenized sample\n",
      "Keys: dict_keys(['text', 'embeddings', 'label', 'input_ids', 'attention_mask'])\n",
      "Input IDs: [101, 1051, 11923, 1012, 2242, 2253, 3308, 1012, 3531, 3046, 2153, 2101, 3504, 2066, 2057, 2024, 2383, 1037, 3291, 2006, 1996, 8241, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length: 512\n"
     ]
    }
   ],
   "source": [
    "# tokenized\n",
    "first_tokenized = tokenized_dataset[\"train\"][0]\n",
    "print(f\"First tokenized sample\")\n",
    "print(f\"Keys: {first_tokenized.keys()}\")\n",
    "print(f\"Input IDs: {first_tokenized['input_ids']}\")\n",
    "print(f\"Attention Mask: {first_tokenized['attention_mask']}\")\n",
    "print(f\"Length: {len(first_tokenized['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric (see the ðŸ¤— Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    pre = precision.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    rec = recall.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "    \n",
    "    # Handle potential None values\n",
    "    results = {\n",
    "        \"accuracy\": acc[\"accuracy\"] if acc else None,\n",
    "        \"f1\": f1_score[\"f1\"] if f1_score else None,\n",
    "        \"precision\": pre[\"precision\"] if pre else None,\n",
    "        \"recall\": rec[\"recall\"] if rec else None,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Finetune the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"real\", 1: \"fake\"}\n",
    "label2id = {\"real\": 0, \"fake\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "You're ready to start training your model now! \n",
    "\n",
    "Load DistilBERT with [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification) along with the number of expected labels, and the label mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, only three steps remain:\n",
    "\n",
    "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the accuracy and save the training checkpoint.\n",
    "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n",
    "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "output_dir = \"checkpoints\"\n",
    "batch_size = 64\n",
    "logging_dir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=logging_dir,\n",
    "    logging_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/142 01:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.497554</td>\n",
       "      <td>0.747495</td>\n",
       "      <td>0.741587</td>\n",
       "      <td>0.745961</td>\n",
       "      <td>0.747495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.499713</td>\n",
       "      <td>0.765531</td>\n",
       "      <td>0.764144</td>\n",
       "      <td>0.763826</td>\n",
       "      <td>0.765531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=142, training_loss=0.3591496240295155, metrics={'train_runtime': 119.1088, 'train_samples_per_second': 75.343, 'train_steps_per_second': 1.192, 'total_flos': 1188762435538944.0, 'train_loss': 0.3591496240295155, 'epoch': 2.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('checkpoints/best_model/tokenizer_config.json',\n",
       " 'checkpoints/best_model/special_tokens_map.json',\n",
       " 'checkpoints/best_model/vocab.txt',\n",
       " 'checkpoints/best_model/added_tokens.json',\n",
       " 'checkpoints/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the best model\n",
    "trainer.save_model(f\"{output_dir}/best_model\")\n",
    "# save the tokenizer\n",
    "tokenizer.save_pretrained(f\"{output_dir}/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics (on testing dataset)\n",
    "- Accuracy\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_result = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4975535571575165,\n",
       " 'eval_accuracy': 0.7474949899799599,\n",
       " 'eval_f1': 0.741586546059846,\n",
       " 'eval_precision': 0.7459606174285781,\n",
       " 'eval_recall': 0.7474949899799599,\n",
       " 'eval_runtime': 2.4395,\n",
       " 'eval_samples_per_second': 204.551,\n",
       " 'eval_steps_per_second': 3.279,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_result, index=[0])\n",
    "test_df.to_csv(f\"{output_dir}/test_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that you've finetuned a model, you can use it for inference!\n",
    "\n",
    "Grab some text you'd like to run inference on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Reports of Lawrence and Pitt dating spread in December 2017. Watch What Happens Live/YouTube and Jason Kempin/Getty Images for Netflix  Jennifer Lawrence appeared on Bravo's \"Watch What Happens Live\" on Thursday, March 1 and responded to the reports that she was dating Brad Pitt.  When a caller asked her if the two stars were \"secretly dating,\" the \"Red Sparrow\" actress denied it.  Even though she says the reports weren't true, Lawrence admitted that she didn't mind the speculation too much.  \"No,\" she said. \"I've met him once in like, 2013, so it was very random, but I also wasn't like, in a hurry to debunk it.\"  In December 2017, it was speculated that Lawrence and Pitt were dating.  In December 2017, it was reported that Jennifer Lawrence was dating Brad Pitt, but the \"Red Sparrow\" actress has now cleared up the speculation and revealed it's not true.  While appearing on Bravo's \"Watch What Happens Live\" on Thursday, Lawrence answered questions from fans who called in, and one viewer from Pennsylvania asked if the reports of her dating Pitt were true. Lawrence denied them, and explained that they only met once a few years ago.  Even though the speculation was false, she admitted that she didn't mind being paired with Pitt.  \"No,\" she said. \"I've met him once in like, 2013, so it was very random, but I also wasn't like, in a hurry to debunk it.\"  Speculation of Lawrence and Pitt dating surfaced in December 2017, with reports stating that Pitt \"had his eye on Jennifer for years\" and they were \"enjoying lots of late nights together.\"  Lawrence has been single since she split with Darren Aronofsky, who directed \"Mother!,\" in 2017 and Pitt has been single since he split with Angelina Jolie in 2016.  Lawrence also isn't the first actor to be linked to Pitt. In November 2017, Kate Hudson appeared on \"Watch What Happens Live\" and addressed the reports that she was dating Pitt. Like Lawrence, she didn't seem to mind the report and called it \"kind of awesome.\"  \"I kind of liked it,\" Hudson said. \"I was like, 'OK, fine. We're having twins!'\"  Sign up here to get INSIDER's favorite stories straight to your inbox.\n"
     ]
    }
   ],
   "source": [
    "text = test_dataset[0][\"text\"]\n",
    "print(f\"Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'fake', 'score': 0.7897346615791321}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=f\"{output_dir}/best_model\", truncation=True, device=device)\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually replicate the results of the `pipeline` if you'd like:\n",
    "\n",
    "Tokenize the text and return PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input keys: dict_keys(['input_ids', 'attention_mask'])\n",
      "Input: {'input_ids': tensor([[  101,  4311,  1997,  5623,  1998, 15091,  5306,  3659,  1999,  2285,\n",
      "          2418,  1012,  3422,  2054,  6433,  2444,  1013,  7858,  1998,  4463,\n",
      "         20441,  2378,  1013,  2131,  3723,  4871,  2005, 20907,  7673,  5623,\n",
      "          2596,  2006, 17562,  1005,  1055,  1000,  3422,  2054,  6433,  2444,\n",
      "          1000,  2006,  9432,  1010,  2233,  1015,  1998,  5838,  2000,  1996,\n",
      "          4311,  2008,  2016,  2001,  5306,  8226, 15091,  1012,  2043,  1037,\n",
      "         20587,  2356,  2014,  2065,  1996,  2048,  3340,  2020,  1000, 10082,\n",
      "          5306,  1010,  1000,  1996,  1000,  2417, 19479,  1000,  3883,  6380,\n",
      "          2009,  1012,  2130,  2295,  2016,  2758,  1996,  4311,  4694,  1005,\n",
      "          1056,  2995,  1010,  5623,  4914,  2008,  2016,  2134,  1005,  1056,\n",
      "          2568,  1996, 12143,  2205,  2172,  1012,  1000,  2053,  1010,  1000,\n",
      "          2016,  2056,  1012,  1000,  1045,  1005,  2310,  2777,  2032,  2320,\n",
      "          1999,  2066,  1010,  2286,  1010,  2061,  2009,  2001,  2200,  6721,\n",
      "          1010,  2021,  1045,  2036,  2347,  1005,  1056,  2066,  1010,  1999,\n",
      "          1037,  9241,  2000,  2139,  8569,  8950,  2009,  1012,  1000,  1999,\n",
      "          2285,  2418,  1010,  2009,  2001, 15520,  2008,  5623,  1998, 15091,\n",
      "          2020,  5306,  1012,  1999,  2285,  2418,  1010,  2009,  2001,  2988,\n",
      "          2008,  7673,  5623,  2001,  5306,  8226, 15091,  1010,  2021,  1996,\n",
      "          1000,  2417, 19479,  1000,  3883,  2038,  2085,  5985,  2039,  1996,\n",
      "         12143,  1998,  3936,  2009,  1005,  1055,  2025,  2995,  1012,  2096,\n",
      "          6037,  2006, 17562,  1005,  1055,  1000,  3422,  2054,  6433,  2444,\n",
      "          1000,  2006,  9432,  1010,  5623,  4660,  3980,  2013,  4599,  2040,\n",
      "          2170,  1999,  1010,  1998,  2028, 13972,  2013,  3552,  2356,  2065,\n",
      "          1996,  4311,  1997,  2014,  5306, 15091,  2020,  2995,  1012,  5623,\n",
      "          6380,  2068,  1010,  1998,  4541,  2008,  2027,  2069,  2777,  2320,\n",
      "          1037,  2261,  2086,  3283,  1012,  2130,  2295,  1996, 12143,  2001,\n",
      "          6270,  1010,  2016,  4914,  2008,  2016,  2134,  1005,  1056,  2568,\n",
      "          2108, 12739,  2007, 15091,  1012,  1000,  2053,  1010,  1000,  2016,\n",
      "          2056,  1012,  1000,  1045,  1005,  2310,  2777,  2032,  2320,  1999,\n",
      "          2066,  1010,  2286,  1010,  2061,  2009,  2001,  2200,  6721,  1010,\n",
      "          2021,  1045,  2036,  2347,  1005,  1056,  2066,  1010,  1999,  1037,\n",
      "          9241,  2000,  2139,  8569,  8950,  2009,  1012,  1000, 12143,  1997,\n",
      "          5623,  1998, 15091,  5306, 15791,  1999,  2285,  2418,  1010,  2007,\n",
      "          4311,  5517,  2008, 15091,  1000,  2018,  2010,  3239,  2006,  7673,\n",
      "          2005,  2086,  1000,  1998,  2027,  2020,  1000,  9107,  7167,  1997,\n",
      "          2397,  6385,  2362,  1012,  1000,  5623,  2038,  2042,  2309,  2144,\n",
      "          2016,  3975,  2007, 12270, 12098, 17175, 10343,  4801,  1010,  2040,\n",
      "          2856,  1000,  2388,   999,  1010,  1000,  1999,  2418,  1998, 15091,\n",
      "          2038,  2042,  2309,  2144,  2002,  3975,  2007, 23847,  8183,  8751,\n",
      "          1999,  2355,  1012,  5623,  2036,  3475,  1005,  1056,  1996,  2034,\n",
      "          3364,  2000,  2022,  5799,  2000, 15091,  1012,  1999,  2281,  2418,\n",
      "          1010,  5736,  6842,  2596,  2006,  1000,  3422,  2054,  6433,  2444,\n",
      "          1000,  1998,  8280,  1996,  4311,  2008,  2016,  2001,  5306, 15091,\n",
      "          1012,  2066,  5623,  1010,  2016,  2134,  1005,  1056,  4025,  2000,\n",
      "          2568,  1996,  3189,  1998,  2170,  2009,  1000,  2785,  1997, 12476,\n",
      "          1012,  1000,  1000,  1045,  2785,  1997,  4669,  2009,  1010,  1000,\n",
      "          6842,  2056,  1012,  1000,  1045,  2001,  2066,  1010,  1005,  7929,\n",
      "          1010,  2986,  1012,  2057,  1005,  2128,  2383,  8178,   999,  1005,\n",
      "          1000,  3696,  2039,  2182,  2000,  2131, 25297,  1005,  1055,  5440,\n",
      "          3441,  3442,  2000,  2115,  1999,  8758,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/best_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "print(f\"Input keys: {inputs.keys()}\")\n",
    "print(f\"Input: {inputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass your inputs to the model and return the `logits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[-0.8020,  0.5214]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"{output_dir}/best_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "print(f\"Logits: {logits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
