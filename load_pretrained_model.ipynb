{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ffb03d5565461caa2c9338e7acca9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/24353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b98e56957d43e990cab3e47a8e722d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6eee613c06440f9023b64988aaf3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/8117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load data\n",
    "dataset = load_dataset(\"GonzaloA/fake_news\", download_mode=\"reuse_cache_if_exists\", cache_dir=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 24353\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print(f\"Dataset: {dataset}\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: JOE DIGENOVA has been around D.C for decades and has seen it all. He probably didn t see his one coming. The incoming president  was set-up to be taken down. A soft coup is in the works and DiGenova has this to say about it:\"It's very clear that they conspired to frame the incoming President of the United States.\"  Joe diGenova on allegations of anti-Trump bias at FBI and TheJusticeDept #Tucker https://t.co/qUNjAenzJc pic.twitter.com/VDlhb45Ghi  G. Ashley Hawkins (@g_ashleyhawkins) December 16, 2017DiGenova on Tucker Carlson tonight: Inside the FBI and Department of Justice under Obama was a brazen plot to do two things. To exonerate Hillary Clinton because of an animous for Donald Trump, and then if she lost to frame the incoming president for either a criminal act or impeachment. This is one of the most disgusting performances by the senior officials at the FBI and the Department of Justice that everyone of these agents should be fired and the people who are still in the Justice Department be fired including Mr. Ohr and they impanel a federal grand jury to investigate the conduct of McCabe and Strzok and Page and Comey and Ohr and everybody in the Obama Justice Department that even touched this. It s very clear that they conspired to frame the incoming president of the United States.DIGENOVA S WIFE VICTORIA TOENSING IS REPRESENTING A FORMER FBI INFORMANT WHO HAS THE GOODS ON THE URANIUM ONE DEAL: DC lawyer Victoria Toensing is one smart cookie. She s representing a former FBI informant who has evidence on kickbacks and bribery involving the transportation of uranium in the US. She recently told Sean Hannity her client will brief Congress about Russian involvement in the U.S. uranium market. This includes widespread bribery and actions that involved the Clintons https://www.youtube.com/watch?v=eDVndQRW22Q I m not going into detail,  attorney Victoria Toensing said on the Oct. 24 Hannity.  You know that, Sean. But the informant will give an overview and specific conversations that he had with Russians in what they were thinking about the money that they were spending. I mean, let me just be that general and it involves the Clintons. The director of the FBI at that time was Robert Mueller, and he is now the special counsel investigating alleged Russian collusion with the 2016 Trump campaign. The undercover investigation involving Toensing s client occurred between 2009 and 2014, and the senior attorney on the case was Rod Rosenstein, who is now the deputy attorney general of the United States and the official who appointed Mueller as special counsel.Further, all this information indicates that many senior Obama administration officials knew about instances of bribery and money laundering involving at least one Russian official, at a time when Russia wanted to expand its uranium market in the United States, and when the administration through a special committee had to approve or deny the sale of a company, Vancouver-based Uranium One, to Rosatom. (Rosatom is the Russian State Atomic Energy Corporation.)Some of the people on that Committee on Foreign Investment in the United States included then-Secretary of State Hillary Clinton, Attorney General Eric Holder, Homeland Security Secretary Janet Napalitano, and Treasury Secretary Timothy Geithner.The committee approved the sale of Uranium One to Rosatom in October 2010. That sale gave Russia, and President Vladimir Putin, control over 20% of U.S. uranium production. (At least nine investors in Uranium One   prior to, during, and after that sale   donated $145 million to the Clinton Foundation.) So, Mueller, [Rod] Rosenstein, maybe even [James] Comey at the time, and the president of the United States   certainly Eric Holder was the head of the DOJ   they all knew that they had all this evidence that the Russians had infiltrated with the purpose of a criminal enterprise to corner the market on uranium, the foundational material of nuclear weapons?  asked Hannity.Toensing said,  That is correct. Via: cns news\n"
     ]
    }
   ],
   "source": [
    "text = test_dataset[0][\"text\"]\n",
    "print(f\"Text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly Text Classification (Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "# ['bert-base-uncased', 'distilbert-base-uncased', 'roberta-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=f\"LittleFish-Coder/{model_name}-fake-news-tfg\", truncation=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'fake', 'score': 0.9998623132705688}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer and Pretrained-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"LittleFish-Coder/{model_name}-fake-news-tfg\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"LittleFish-Coder/{model_name}-fake-news-tfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict via tokenizer & model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the text and get the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: fake\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "prediction = model.config.id2label[predicted_class_id]\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the embedding of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.output_hidden_states = True\n",
    "\n",
    "# Get model output with hidden states\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Now, outputs will have the hidden states\n",
    "hidden_states = outputs.hidden_states\n",
    "\n",
    "# The last layer's hidden state can be accessed like this\n",
    "last_hidden_state = hidden_states[-1]\n",
    "\n",
    "# If you still want to extract embeddings similar to the previous approach\n",
    "embeddings = last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([1, 768])\n",
      "Embeddings: tensor([[-2.9920e-02, -1.7140e-01,  2.7610e-01,  1.0799e-01, -1.0619e+00,\n",
      "          1.6642e+00, -3.8511e-01, -6.5864e-01, -2.8680e-01, -4.4714e-01,\n",
      "         -4.9551e-01, -3.3066e-01, -1.0937e-01,  5.8195e-01,  9.2182e-01,\n",
      "          3.2029e-01, -4.4218e-02,  4.2980e-01, -8.0234e-01, -8.4733e-01,\n",
      "          2.7803e-01,  4.9765e-01,  9.9182e-01,  7.6151e-01, -4.2630e-01,\n",
      "         -1.5596e+00,  6.4133e-01, -1.2850e-01, -1.7808e-01, -7.2685e-02,\n",
      "         -1.3189e-01, -4.5664e-01, -6.0735e-02,  1.3563e-01,  8.8216e-01,\n",
      "          1.4637e+00,  1.5257e+00, -1.4174e-01,  4.6739e-01,  2.6380e-01,\n",
      "         -1.2061e+00,  1.7454e+00, -1.1629e+00, -8.5190e-01,  7.8971e-01,\n",
      "          4.3815e-01,  1.1670e+00,  1.4467e+00,  9.8973e-01, -1.3201e-01,\n",
      "         -1.8164e-01, -1.9481e+00, -1.2132e+00,  2.3281e-01, -1.2659e+00,\n",
      "         -7.7241e-02, -8.6417e-01,  2.3744e-01, -3.7228e-01, -6.6503e-01,\n",
      "         -6.3943e-01,  1.2179e+00,  9.7103e-01,  5.4843e-01,  2.1289e-01,\n",
      "          3.8979e-01,  9.1268e-01,  1.2833e+00, -3.2161e-01,  3.9206e-01,\n",
      "          3.0421e-01, -3.4083e-01, -3.7017e-01, -1.7976e-01,  5.9099e-01,\n",
      "          1.2441e-01, -5.7385e-01, -2.1778e+00, -7.4048e-01,  9.4229e-02,\n",
      "          8.7966e-01, -3.7201e-01,  8.6727e-01,  5.1371e-01,  7.7790e-01,\n",
      "         -1.3694e+00,  3.3714e-01,  8.4237e-01,  9.9465e-01,  1.1658e+00,\n",
      "          5.7028e-02, -1.2584e+00,  7.9649e-02, -3.3348e-01, -4.9654e-01,\n",
      "         -2.3040e-01,  1.8988e-01, -1.7489e+00,  2.2188e-01, -1.2881e-01,\n",
      "          1.3181e+00, -8.0455e-02, -2.7814e-01, -2.5536e-02,  1.2850e-01,\n",
      "         -1.2406e+00,  8.1349e-01, -2.6669e-01, -1.5915e-01,  1.0696e+00,\n",
      "         -3.2895e-01,  1.2179e-01,  3.4594e-02, -1.2484e-01,  4.8809e-01,\n",
      "          6.5756e-02, -8.5156e-02, -4.4583e-01,  3.3167e-01,  9.5494e-01,\n",
      "          1.3004e+00,  5.8501e-01,  1.1183e+00,  4.2959e-02, -7.0976e-02,\n",
      "          5.0054e-01,  6.5385e-01,  8.5610e-01,  8.9218e-03, -1.3166e+00,\n",
      "         -3.5966e-01, -1.9078e+00, -3.3943e-01, -3.5228e-01,  1.4591e+00,\n",
      "         -2.5228e-01, -3.4144e-02,  3.0263e-01,  5.4931e-01, -5.3144e-01,\n",
      "         -8.3921e-01,  4.5101e-01,  3.4054e-01, -1.6696e-02, -4.5254e-01,\n",
      "          3.9292e-01, -4.5783e-01, -2.3296e-01, -2.1618e-01,  4.3396e-02,\n",
      "          1.2392e+00, -7.8304e-01, -1.2984e+00, -1.5304e+00, -5.1569e-01,\n",
      "         -1.1391e+00, -2.3482e-01,  3.2524e-01,  1.1909e+00,  3.2251e-01,\n",
      "          6.9762e-01, -8.3697e-01,  7.1901e-01, -1.3249e-01,  1.7203e+00,\n",
      "          1.6776e-01,  2.1195e-01,  6.4297e-01,  1.4011e+00,  1.7833e-03,\n",
      "          9.3897e-02, -5.2918e-01,  4.6730e-01, -4.7027e-01, -8.3164e-01,\n",
      "         -4.5965e-01,  9.4075e-01,  3.2222e-01, -6.4567e-01,  1.9954e-01,\n",
      "         -7.0939e-02,  6.4859e-01,  1.0006e-01,  4.7093e-01,  4.1934e-01,\n",
      "         -3.3549e-01, -7.6129e-01, -6.2862e-01, -3.2313e-01,  8.5547e-01,\n",
      "         -1.1899e+00,  3.5410e-01, -8.4001e-01, -1.5052e-01,  1.1051e+00,\n",
      "         -1.9003e-01, -3.6354e-01, -7.1668e-01,  7.4922e-01,  1.4851e-01,\n",
      "          2.2435e+00, -8.3074e-01, -7.1234e-01, -1.4299e+00, -1.4346e+00,\n",
      "          5.2076e-01,  1.5148e+00,  2.6292e-01, -1.8592e-03, -2.3047e-01,\n",
      "         -2.6408e-01, -1.6685e+00, -3.1473e-01,  3.4677e-01,  3.4643e-01,\n",
      "         -3.9576e-01,  8.8689e-01, -2.2198e+00,  5.4826e-01, -3.3154e-01,\n",
      "          1.5083e-01,  1.2032e+00,  2.7569e-01,  1.0404e+00, -6.4171e-01,\n",
      "         -1.5318e-01, -1.0175e+00,  1.1054e+00,  3.8279e-01,  2.6347e-01,\n",
      "         -4.0028e-01, -1.3778e+00, -1.8640e-01, -7.4283e-01, -1.4017e-01,\n",
      "         -2.5851e-01, -5.7468e-01, -4.1489e-01, -2.8249e-01, -4.5068e-02,\n",
      "         -6.2925e-01,  2.6401e-01,  8.1165e-01, -1.1402e+00,  2.2479e-01,\n",
      "         -4.5415e-01, -7.4711e-02, -2.0267e+00,  1.4204e+00,  6.0609e-01,\n",
      "         -7.9672e-01, -1.6383e+00, -6.0245e-02,  2.4038e-01, -3.4814e-01,\n",
      "          6.8097e-01, -4.5403e-01, -1.0928e+00,  4.7077e-01, -1.6146e+00,\n",
      "          1.2369e-01,  3.7053e-02,  1.3414e+00,  7.7947e-02,  4.2575e-01,\n",
      "         -4.3173e-01,  5.6957e-01,  9.0268e-02,  5.3564e-01,  5.3331e-02,\n",
      "          3.1493e-01, -4.6730e-01,  4.5139e-01, -1.1106e+00,  3.8504e-01,\n",
      "          2.3328e-01, -9.5437e-01, -4.0868e-01,  8.8362e-01,  3.3264e-01,\n",
      "          1.8296e-01,  3.6902e-01, -1.7880e+00,  2.3341e-01,  1.0989e+00,\n",
      "          3.2686e-01, -1.0152e-01, -5.1305e-01, -9.1323e-01,  2.9131e-01,\n",
      "          1.4997e-01, -7.0078e-01, -4.5285e-01, -8.9282e-01, -2.2210e-01,\n",
      "          5.0431e-01, -9.6374e-01, -1.7794e-01, -9.3103e-02,  5.1292e-01,\n",
      "         -8.9098e-01,  1.3777e+00,  1.1008e+00,  1.2977e+00, -3.2990e-01,\n",
      "          2.2072e+00, -1.4602e-01, -4.3203e-01,  4.3982e-01,  1.3016e+00,\n",
      "         -4.4284e-01,  2.6544e-01, -4.3312e-01,  3.8382e-01, -7.2593e-01,\n",
      "          1.0581e+00, -1.4831e-01, -8.0685e-01, -2.5219e-01, -1.0059e+00,\n",
      "         -8.3831e-01,  3.0268e-01,  2.1766e-01,  1.1747e-01,  9.3815e-02,\n",
      "          7.1909e-01, -2.0922e-01, -9.9898e-01,  1.4876e+00, -3.1106e-01,\n",
      "          2.9139e-01, -2.1659e-01, -3.9529e-01,  8.6004e-01,  3.4969e-01,\n",
      "         -1.2886e-01, -5.4285e-01, -3.2838e-01,  6.1124e-01,  2.2906e-01,\n",
      "         -9.5866e-02, -1.0108e+00, -2.0293e-02,  2.6052e-01,  3.1185e-01,\n",
      "          1.6935e+00,  7.7058e-01,  1.1751e-01, -9.7784e-02,  3.0242e-01,\n",
      "         -1.5665e+00,  4.5107e-01, -1.1315e+00, -7.1667e-01,  6.5999e-01,\n",
      "          1.5946e+00,  2.7386e-01,  3.4203e-01, -5.0703e-01, -7.3267e-01,\n",
      "         -1.0517e+00, -4.3742e-01, -4.4528e-01,  3.6120e-01, -4.9101e-01,\n",
      "          1.2675e+00,  2.5587e-01,  5.5345e-01,  1.4648e-01, -4.0040e-01,\n",
      "         -7.1862e-01,  5.6186e-01,  1.1760e+00, -7.9357e-01,  1.4917e-01,\n",
      "          1.1395e-01,  8.2268e-01,  2.5739e-01,  1.3728e-01, -3.1951e-01,\n",
      "         -2.7797e-01, -3.8943e-01,  5.7871e-02,  7.6414e-01,  1.0700e+00,\n",
      "          1.1302e+00,  2.3253e+00,  4.4379e-01, -5.3667e-01,  1.7966e-02,\n",
      "          1.1281e+00, -1.3743e-01, -1.2882e-01,  4.0521e-01,  9.7469e-01,\n",
      "          8.4267e-01,  4.9649e-01,  1.8491e+00,  9.0809e-01, -1.0543e+00,\n",
      "         -4.6979e-01,  1.3087e+00,  2.7567e-01,  2.2481e-01, -7.2103e-01,\n",
      "         -1.1852e+00, -3.4042e-01, -1.9307e-02,  1.0182e+00,  5.6765e-02,\n",
      "          1.7315e-01,  2.3656e-01,  1.6926e-01, -6.8593e-02,  3.9567e-01,\n",
      "         -8.3943e-01, -5.2205e-01,  2.8359e-01, -4.5817e-01, -1.2280e-01,\n",
      "          1.0439e+00,  1.9892e-02, -6.6921e-01,  7.3285e-01, -1.3014e-02,\n",
      "          1.0837e+00, -4.5938e-01, -4.5115e-01, -2.8037e-01, -2.9719e-01,\n",
      "         -1.3126e-01, -1.3670e+00, -5.6388e-01,  6.0720e-01, -6.1847e-01,\n",
      "         -7.1072e-01,  8.1482e-01, -4.5747e-01,  9.4719e-01, -9.4995e-01,\n",
      "          1.5481e+00,  3.3326e-01,  2.7636e-01,  6.0643e-01,  5.2941e-01,\n",
      "         -3.3687e-01, -5.6092e-01,  6.3131e-02,  3.5353e-01, -3.6650e-01,\n",
      "         -4.9419e-01,  6.9313e-01,  1.0686e+00, -1.4802e+00,  1.3544e+00,\n",
      "         -1.0689e+00,  3.8249e-01,  3.8737e-01,  1.5271e+00,  1.7278e-01,\n",
      "         -2.8111e-01, -3.6945e-01,  3.3908e-02, -2.9582e-01,  2.5877e-01,\n",
      "         -1.1864e+00,  2.1022e-01,  1.1232e+00, -1.7872e+00,  8.9879e-02,\n",
      "         -1.6656e-01,  1.7488e-01,  2.6842e-01, -2.3144e-01,  1.3812e+00,\n",
      "         -4.4093e-01,  1.0373e+00, -9.9322e-01,  4.8219e-01, -4.3377e-01,\n",
      "          4.6804e-01, -5.2231e-01,  1.1299e+00,  1.8435e-01, -1.2247e-01,\n",
      "          2.3908e-01, -9.2600e-02, -5.1045e-01,  6.5130e-01, -6.1670e-02,\n",
      "         -4.3222e-01,  1.2779e+00,  1.2289e+00,  1.1965e+00, -5.0688e-01,\n",
      "          6.2469e-03, -1.1416e+00, -1.7136e+00,  4.7078e-01, -1.0670e+00,\n",
      "          3.9655e-01,  5.3580e-01,  6.9273e-01, -1.7591e-01,  4.1201e-01,\n",
      "         -5.1266e-01,  5.8652e-01, -1.2700e+00,  6.7606e-01,  1.0139e+00,\n",
      "          8.3474e-01,  1.5127e-02, -9.8099e-01, -8.8065e-01,  7.6119e-01,\n",
      "          1.4001e-01, -2.6197e-01,  1.0295e-01,  2.3447e-01,  6.1024e-01,\n",
      "         -9.2866e-01,  8.9577e-01, -1.5685e-01,  1.5902e+00, -1.9401e-02,\n",
      "         -1.1697e+00,  3.1126e-01, -9.1356e-01, -1.6343e+00,  7.5735e-01,\n",
      "          9.6419e-01, -3.2766e+00,  5.4305e-03, -4.1533e-01, -1.0853e+00,\n",
      "         -3.7609e-02,  4.6207e-01,  9.1913e-01,  4.4777e-02,  1.6542e+00,\n",
      "          4.7969e-01, -1.4106e+00,  1.2037e+00,  3.2582e-01, -1.5999e-01,\n",
      "          6.5780e-01,  1.8399e+00, -2.2027e-01,  4.3599e-01, -9.6727e-01,\n",
      "          6.9422e-01,  2.0100e+00,  3.8536e-01,  1.5631e-01, -3.3712e-02,\n",
      "          1.1297e-01, -1.9549e-01,  1.7424e+00,  2.1934e-01, -9.7754e-03,\n",
      "          5.5408e-01, -6.5049e-01, -1.0223e+00, -1.5753e-01,  1.8053e-01,\n",
      "          8.2333e-01,  6.0982e-01,  8.1032e-02, -4.5941e-01, -8.4655e-01,\n",
      "         -9.0543e-01,  1.6248e+00,  8.5328e-01,  1.7834e-01, -1.1250e+00,\n",
      "         -4.1159e-01, -7.1664e-01, -2.5455e+00,  7.5144e-01, -5.6487e-03,\n",
      "          6.5624e-02,  1.4428e+00,  1.5437e+00,  4.9925e-01,  4.0970e-01,\n",
      "          1.2795e-01,  2.6950e-01,  1.0765e+00,  6.2609e-01,  9.1280e-02,\n",
      "          1.0791e+00, -1.5841e+00,  1.3276e+00,  5.2408e-01,  9.8074e-01,\n",
      "         -4.4823e-01,  1.3999e+00, -3.2969e-01, -3.7642e-01, -5.8693e-01,\n",
      "         -8.3709e-01,  4.9548e-01,  3.4328e-02,  7.9406e-01, -6.9217e-02,\n",
      "          5.4665e-01, -5.6961e-01, -3.4165e-01, -7.0314e-01,  1.1514e-01,\n",
      "          8.8695e-02,  1.1529e+00, -7.4040e-01,  2.7425e-01,  2.4951e-01,\n",
      "         -7.5082e-01, -1.2410e+00, -7.5319e-02, -9.8871e-02,  1.5437e+00,\n",
      "          3.8647e-01,  8.6531e-01,  5.5049e-01,  4.8102e-01,  1.3136e+00,\n",
      "         -2.3082e-01,  1.2079e+00, -3.2315e-01, -7.5415e-01,  3.1139e-01,\n",
      "          2.7518e-01,  1.1504e+00,  1.6942e-01, -1.2342e+00, -2.0119e-01,\n",
      "          1.4015e+00,  7.0022e-01,  9.5294e-02,  3.9461e-01,  5.9953e-02,\n",
      "         -3.7333e-01, -2.7713e-01,  5.6469e-01,  7.1848e-01, -3.5112e-02,\n",
      "         -3.0243e-02, -7.9995e-02, -1.0461e+00,  7.3379e-01,  2.3326e-02,\n",
      "         -1.3541e+00, -1.1071e-01,  3.4700e-01,  4.3366e-01,  3.3141e-02,\n",
      "          1.1039e+00, -2.7429e-01,  4.3991e-01,  1.3297e-01, -1.0629e-01,\n",
      "         -4.1794e-01, -2.4515e-01, -5.0066e-01, -1.3271e+00,  7.5702e-01,\n",
      "         -4.6801e-01, -1.0253e+00,  2.8837e-01, -7.3138e-01, -4.0601e-01,\n",
      "          5.1995e-02, -6.2848e-01, -5.2722e-01,  1.0564e-01, -2.7567e-01,\n",
      "          4.5276e-01, -5.4494e-01, -6.3616e-01, -5.1597e-01,  2.1574e+00,\n",
      "          2.8825e-01,  2.2572e-01, -9.7179e-01, -7.5433e-01, -1.3276e-01,\n",
      "          4.8928e-02, -1.3791e+00,  1.9060e-01, -1.0415e+00, -6.3420e-01,\n",
      "         -8.3158e-01, -9.6967e-02,  1.0118e+00,  4.3609e-01,  4.6757e-01,\n",
      "         -1.2281e-01,  6.8141e-01,  4.3602e-01, -9.0663e-02, -3.7942e-01,\n",
      "         -4.3668e-01, -4.5740e-01, -3.7599e-01, -5.7632e-01,  1.1345e-01,\n",
      "         -1.7867e+00,  1.1908e-01, -8.4322e-02, -2.5107e-01,  5.9714e-01,\n",
      "         -3.4063e-01, -3.4361e-01, -1.5082e-01, -5.7989e-01, -7.9056e-02,\n",
      "         -7.1118e-01,  3.5589e-03,  1.2856e-01,  1.0480e+00, -3.5306e-01,\n",
      "         -3.7980e-01, -5.3804e-01, -5.8976e-01, -4.9803e-01,  2.6539e-01,\n",
      "          9.3087e-01,  1.0034e+00, -6.5383e-02,  3.8672e-01,  1.2677e+00,\n",
      "          3.5451e-01, -1.2184e+00, -2.2654e-01, -7.5529e-01,  4.2641e-01,\n",
      "          1.3579e+00,  3.2172e-01, -5.6564e-01,  3.0768e-01,  1.6686e+00,\n",
      "          1.3896e+00, -1.2565e+00,  2.2870e-01,  1.2295e+00, -5.0728e-01,\n",
      "          6.7308e-01,  7.5250e-01, -5.3082e-01,  4.2679e-01, -6.0367e-01,\n",
      "         -5.4101e-02, -3.1752e-01, -1.4701e+00,  1.6440e-01,  1.8439e-01,\n",
      "         -7.5211e-01,  7.1648e-01,  5.6180e-01, -3.8971e-01, -2.1763e-02,\n",
      "         -2.6344e-01,  4.3540e-01,  5.9147e-01,  5.4556e-01, -1.0154e+00,\n",
      "         -9.6374e-01,  7.6213e-01, -7.6375e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings: {embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at LittleFish-Coder/roberta-base-fake-news-tfg and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"LittleFish-Coder/{model_name}-fake-news-tfg\")\n",
    "# Load the base model as an encoder\n",
    "model = AutoModel.from_pretrained(f\"LittleFish-Coder/{model_name}-fake-news-tfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model(**inputs).last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([1, 768])\n",
      "Embeddings: tensor([[-2.9920e-02, -1.7140e-01,  2.7610e-01,  1.0799e-01, -1.0619e+00,\n",
      "          1.6642e+00, -3.8511e-01, -6.5864e-01, -2.8680e-01, -4.4714e-01,\n",
      "         -4.9551e-01, -3.3066e-01, -1.0937e-01,  5.8195e-01,  9.2182e-01,\n",
      "          3.2029e-01, -4.4218e-02,  4.2980e-01, -8.0234e-01, -8.4733e-01,\n",
      "          2.7803e-01,  4.9765e-01,  9.9182e-01,  7.6151e-01, -4.2630e-01,\n",
      "         -1.5596e+00,  6.4133e-01, -1.2850e-01, -1.7808e-01, -7.2685e-02,\n",
      "         -1.3189e-01, -4.5664e-01, -6.0735e-02,  1.3563e-01,  8.8216e-01,\n",
      "          1.4637e+00,  1.5257e+00, -1.4174e-01,  4.6739e-01,  2.6380e-01,\n",
      "         -1.2061e+00,  1.7454e+00, -1.1629e+00, -8.5190e-01,  7.8971e-01,\n",
      "          4.3815e-01,  1.1670e+00,  1.4467e+00,  9.8973e-01, -1.3201e-01,\n",
      "         -1.8164e-01, -1.9481e+00, -1.2132e+00,  2.3281e-01, -1.2659e+00,\n",
      "         -7.7241e-02, -8.6417e-01,  2.3744e-01, -3.7228e-01, -6.6503e-01,\n",
      "         -6.3943e-01,  1.2179e+00,  9.7103e-01,  5.4843e-01,  2.1289e-01,\n",
      "          3.8979e-01,  9.1268e-01,  1.2833e+00, -3.2161e-01,  3.9206e-01,\n",
      "          3.0421e-01, -3.4083e-01, -3.7017e-01, -1.7976e-01,  5.9099e-01,\n",
      "          1.2441e-01, -5.7385e-01, -2.1778e+00, -7.4048e-01,  9.4229e-02,\n",
      "          8.7966e-01, -3.7201e-01,  8.6727e-01,  5.1371e-01,  7.7790e-01,\n",
      "         -1.3694e+00,  3.3714e-01,  8.4237e-01,  9.9465e-01,  1.1658e+00,\n",
      "          5.7028e-02, -1.2584e+00,  7.9649e-02, -3.3348e-01, -4.9654e-01,\n",
      "         -2.3040e-01,  1.8988e-01, -1.7489e+00,  2.2188e-01, -1.2881e-01,\n",
      "          1.3181e+00, -8.0455e-02, -2.7814e-01, -2.5536e-02,  1.2850e-01,\n",
      "         -1.2406e+00,  8.1349e-01, -2.6669e-01, -1.5915e-01,  1.0696e+00,\n",
      "         -3.2895e-01,  1.2179e-01,  3.4594e-02, -1.2484e-01,  4.8809e-01,\n",
      "          6.5756e-02, -8.5156e-02, -4.4583e-01,  3.3167e-01,  9.5494e-01,\n",
      "          1.3004e+00,  5.8501e-01,  1.1183e+00,  4.2959e-02, -7.0976e-02,\n",
      "          5.0054e-01,  6.5385e-01,  8.5610e-01,  8.9218e-03, -1.3166e+00,\n",
      "         -3.5966e-01, -1.9078e+00, -3.3943e-01, -3.5228e-01,  1.4591e+00,\n",
      "         -2.5228e-01, -3.4144e-02,  3.0263e-01,  5.4931e-01, -5.3144e-01,\n",
      "         -8.3921e-01,  4.5101e-01,  3.4054e-01, -1.6696e-02, -4.5254e-01,\n",
      "          3.9292e-01, -4.5783e-01, -2.3296e-01, -2.1618e-01,  4.3396e-02,\n",
      "          1.2392e+00, -7.8304e-01, -1.2984e+00, -1.5304e+00, -5.1569e-01,\n",
      "         -1.1391e+00, -2.3482e-01,  3.2524e-01,  1.1909e+00,  3.2251e-01,\n",
      "          6.9762e-01, -8.3697e-01,  7.1901e-01, -1.3249e-01,  1.7203e+00,\n",
      "          1.6776e-01,  2.1195e-01,  6.4297e-01,  1.4011e+00,  1.7833e-03,\n",
      "          9.3897e-02, -5.2918e-01,  4.6730e-01, -4.7027e-01, -8.3164e-01,\n",
      "         -4.5965e-01,  9.4075e-01,  3.2222e-01, -6.4567e-01,  1.9954e-01,\n",
      "         -7.0939e-02,  6.4859e-01,  1.0006e-01,  4.7093e-01,  4.1934e-01,\n",
      "         -3.3549e-01, -7.6129e-01, -6.2862e-01, -3.2313e-01,  8.5547e-01,\n",
      "         -1.1899e+00,  3.5410e-01, -8.4001e-01, -1.5052e-01,  1.1051e+00,\n",
      "         -1.9003e-01, -3.6354e-01, -7.1668e-01,  7.4922e-01,  1.4851e-01,\n",
      "          2.2435e+00, -8.3074e-01, -7.1234e-01, -1.4299e+00, -1.4346e+00,\n",
      "          5.2076e-01,  1.5148e+00,  2.6292e-01, -1.8592e-03, -2.3047e-01,\n",
      "         -2.6408e-01, -1.6685e+00, -3.1473e-01,  3.4677e-01,  3.4643e-01,\n",
      "         -3.9576e-01,  8.8689e-01, -2.2198e+00,  5.4826e-01, -3.3154e-01,\n",
      "          1.5083e-01,  1.2032e+00,  2.7569e-01,  1.0404e+00, -6.4171e-01,\n",
      "         -1.5318e-01, -1.0175e+00,  1.1054e+00,  3.8279e-01,  2.6347e-01,\n",
      "         -4.0028e-01, -1.3778e+00, -1.8640e-01, -7.4283e-01, -1.4017e-01,\n",
      "         -2.5851e-01, -5.7468e-01, -4.1489e-01, -2.8249e-01, -4.5068e-02,\n",
      "         -6.2925e-01,  2.6401e-01,  8.1165e-01, -1.1402e+00,  2.2479e-01,\n",
      "         -4.5415e-01, -7.4711e-02, -2.0267e+00,  1.4204e+00,  6.0609e-01,\n",
      "         -7.9672e-01, -1.6383e+00, -6.0245e-02,  2.4038e-01, -3.4814e-01,\n",
      "          6.8097e-01, -4.5403e-01, -1.0928e+00,  4.7077e-01, -1.6146e+00,\n",
      "          1.2369e-01,  3.7053e-02,  1.3414e+00,  7.7947e-02,  4.2575e-01,\n",
      "         -4.3173e-01,  5.6957e-01,  9.0268e-02,  5.3564e-01,  5.3331e-02,\n",
      "          3.1493e-01, -4.6730e-01,  4.5139e-01, -1.1106e+00,  3.8504e-01,\n",
      "          2.3328e-01, -9.5437e-01, -4.0868e-01,  8.8362e-01,  3.3264e-01,\n",
      "          1.8296e-01,  3.6902e-01, -1.7880e+00,  2.3341e-01,  1.0989e+00,\n",
      "          3.2686e-01, -1.0152e-01, -5.1305e-01, -9.1323e-01,  2.9131e-01,\n",
      "          1.4997e-01, -7.0078e-01, -4.5285e-01, -8.9282e-01, -2.2210e-01,\n",
      "          5.0431e-01, -9.6374e-01, -1.7794e-01, -9.3103e-02,  5.1292e-01,\n",
      "         -8.9098e-01,  1.3777e+00,  1.1008e+00,  1.2977e+00, -3.2990e-01,\n",
      "          2.2072e+00, -1.4602e-01, -4.3203e-01,  4.3982e-01,  1.3016e+00,\n",
      "         -4.4284e-01,  2.6544e-01, -4.3312e-01,  3.8382e-01, -7.2593e-01,\n",
      "          1.0581e+00, -1.4831e-01, -8.0685e-01, -2.5219e-01, -1.0059e+00,\n",
      "         -8.3831e-01,  3.0268e-01,  2.1766e-01,  1.1747e-01,  9.3815e-02,\n",
      "          7.1909e-01, -2.0922e-01, -9.9898e-01,  1.4876e+00, -3.1106e-01,\n",
      "          2.9139e-01, -2.1659e-01, -3.9529e-01,  8.6004e-01,  3.4969e-01,\n",
      "         -1.2886e-01, -5.4285e-01, -3.2838e-01,  6.1124e-01,  2.2906e-01,\n",
      "         -9.5866e-02, -1.0108e+00, -2.0293e-02,  2.6052e-01,  3.1185e-01,\n",
      "          1.6935e+00,  7.7058e-01,  1.1751e-01, -9.7784e-02,  3.0242e-01,\n",
      "         -1.5665e+00,  4.5107e-01, -1.1315e+00, -7.1667e-01,  6.5999e-01,\n",
      "          1.5946e+00,  2.7386e-01,  3.4203e-01, -5.0703e-01, -7.3267e-01,\n",
      "         -1.0517e+00, -4.3742e-01, -4.4528e-01,  3.6120e-01, -4.9101e-01,\n",
      "          1.2675e+00,  2.5587e-01,  5.5345e-01,  1.4648e-01, -4.0040e-01,\n",
      "         -7.1862e-01,  5.6186e-01,  1.1760e+00, -7.9357e-01,  1.4917e-01,\n",
      "          1.1395e-01,  8.2268e-01,  2.5739e-01,  1.3728e-01, -3.1951e-01,\n",
      "         -2.7797e-01, -3.8943e-01,  5.7871e-02,  7.6414e-01,  1.0700e+00,\n",
      "          1.1302e+00,  2.3253e+00,  4.4379e-01, -5.3667e-01,  1.7966e-02,\n",
      "          1.1281e+00, -1.3743e-01, -1.2882e-01,  4.0521e-01,  9.7469e-01,\n",
      "          8.4267e-01,  4.9649e-01,  1.8491e+00,  9.0809e-01, -1.0543e+00,\n",
      "         -4.6979e-01,  1.3087e+00,  2.7567e-01,  2.2481e-01, -7.2103e-01,\n",
      "         -1.1852e+00, -3.4042e-01, -1.9307e-02,  1.0182e+00,  5.6765e-02,\n",
      "          1.7315e-01,  2.3656e-01,  1.6926e-01, -6.8593e-02,  3.9567e-01,\n",
      "         -8.3943e-01, -5.2205e-01,  2.8359e-01, -4.5817e-01, -1.2280e-01,\n",
      "          1.0439e+00,  1.9892e-02, -6.6921e-01,  7.3285e-01, -1.3014e-02,\n",
      "          1.0837e+00, -4.5938e-01, -4.5115e-01, -2.8037e-01, -2.9719e-01,\n",
      "         -1.3126e-01, -1.3670e+00, -5.6388e-01,  6.0720e-01, -6.1847e-01,\n",
      "         -7.1072e-01,  8.1482e-01, -4.5747e-01,  9.4719e-01, -9.4995e-01,\n",
      "          1.5481e+00,  3.3326e-01,  2.7636e-01,  6.0643e-01,  5.2941e-01,\n",
      "         -3.3687e-01, -5.6092e-01,  6.3131e-02,  3.5353e-01, -3.6650e-01,\n",
      "         -4.9419e-01,  6.9313e-01,  1.0686e+00, -1.4802e+00,  1.3544e+00,\n",
      "         -1.0689e+00,  3.8249e-01,  3.8737e-01,  1.5271e+00,  1.7278e-01,\n",
      "         -2.8111e-01, -3.6945e-01,  3.3908e-02, -2.9582e-01,  2.5877e-01,\n",
      "         -1.1864e+00,  2.1022e-01,  1.1232e+00, -1.7872e+00,  8.9879e-02,\n",
      "         -1.6656e-01,  1.7488e-01,  2.6842e-01, -2.3144e-01,  1.3812e+00,\n",
      "         -4.4093e-01,  1.0373e+00, -9.9322e-01,  4.8219e-01, -4.3377e-01,\n",
      "          4.6804e-01, -5.2231e-01,  1.1299e+00,  1.8435e-01, -1.2247e-01,\n",
      "          2.3908e-01, -9.2600e-02, -5.1045e-01,  6.5130e-01, -6.1670e-02,\n",
      "         -4.3222e-01,  1.2779e+00,  1.2289e+00,  1.1965e+00, -5.0688e-01,\n",
      "          6.2469e-03, -1.1416e+00, -1.7136e+00,  4.7078e-01, -1.0670e+00,\n",
      "          3.9655e-01,  5.3580e-01,  6.9273e-01, -1.7591e-01,  4.1201e-01,\n",
      "         -5.1266e-01,  5.8652e-01, -1.2700e+00,  6.7606e-01,  1.0139e+00,\n",
      "          8.3474e-01,  1.5127e-02, -9.8099e-01, -8.8065e-01,  7.6119e-01,\n",
      "          1.4001e-01, -2.6197e-01,  1.0295e-01,  2.3447e-01,  6.1024e-01,\n",
      "         -9.2866e-01,  8.9577e-01, -1.5685e-01,  1.5902e+00, -1.9401e-02,\n",
      "         -1.1697e+00,  3.1126e-01, -9.1356e-01, -1.6343e+00,  7.5735e-01,\n",
      "          9.6419e-01, -3.2766e+00,  5.4305e-03, -4.1533e-01, -1.0853e+00,\n",
      "         -3.7609e-02,  4.6207e-01,  9.1913e-01,  4.4777e-02,  1.6542e+00,\n",
      "          4.7969e-01, -1.4106e+00,  1.2037e+00,  3.2582e-01, -1.5999e-01,\n",
      "          6.5780e-01,  1.8399e+00, -2.2027e-01,  4.3599e-01, -9.6727e-01,\n",
      "          6.9422e-01,  2.0100e+00,  3.8536e-01,  1.5631e-01, -3.3712e-02,\n",
      "          1.1297e-01, -1.9549e-01,  1.7424e+00,  2.1934e-01, -9.7754e-03,\n",
      "          5.5408e-01, -6.5049e-01, -1.0223e+00, -1.5753e-01,  1.8053e-01,\n",
      "          8.2333e-01,  6.0982e-01,  8.1032e-02, -4.5941e-01, -8.4655e-01,\n",
      "         -9.0543e-01,  1.6248e+00,  8.5328e-01,  1.7834e-01, -1.1250e+00,\n",
      "         -4.1159e-01, -7.1664e-01, -2.5455e+00,  7.5144e-01, -5.6487e-03,\n",
      "          6.5624e-02,  1.4428e+00,  1.5437e+00,  4.9925e-01,  4.0970e-01,\n",
      "          1.2795e-01,  2.6950e-01,  1.0765e+00,  6.2609e-01,  9.1280e-02,\n",
      "          1.0791e+00, -1.5841e+00,  1.3276e+00,  5.2408e-01,  9.8074e-01,\n",
      "         -4.4823e-01,  1.3999e+00, -3.2969e-01, -3.7642e-01, -5.8693e-01,\n",
      "         -8.3709e-01,  4.9548e-01,  3.4328e-02,  7.9406e-01, -6.9217e-02,\n",
      "          5.4665e-01, -5.6961e-01, -3.4165e-01, -7.0314e-01,  1.1514e-01,\n",
      "          8.8695e-02,  1.1529e+00, -7.4040e-01,  2.7425e-01,  2.4951e-01,\n",
      "         -7.5082e-01, -1.2410e+00, -7.5319e-02, -9.8871e-02,  1.5437e+00,\n",
      "          3.8647e-01,  8.6531e-01,  5.5049e-01,  4.8102e-01,  1.3136e+00,\n",
      "         -2.3082e-01,  1.2079e+00, -3.2315e-01, -7.5415e-01,  3.1139e-01,\n",
      "          2.7518e-01,  1.1504e+00,  1.6942e-01, -1.2342e+00, -2.0119e-01,\n",
      "          1.4015e+00,  7.0022e-01,  9.5294e-02,  3.9461e-01,  5.9953e-02,\n",
      "         -3.7333e-01, -2.7713e-01,  5.6469e-01,  7.1848e-01, -3.5112e-02,\n",
      "         -3.0243e-02, -7.9995e-02, -1.0461e+00,  7.3379e-01,  2.3326e-02,\n",
      "         -1.3541e+00, -1.1071e-01,  3.4700e-01,  4.3366e-01,  3.3141e-02,\n",
      "          1.1039e+00, -2.7429e-01,  4.3991e-01,  1.3297e-01, -1.0629e-01,\n",
      "         -4.1794e-01, -2.4515e-01, -5.0066e-01, -1.3271e+00,  7.5702e-01,\n",
      "         -4.6801e-01, -1.0253e+00,  2.8837e-01, -7.3138e-01, -4.0601e-01,\n",
      "          5.1995e-02, -6.2848e-01, -5.2722e-01,  1.0564e-01, -2.7567e-01,\n",
      "          4.5276e-01, -5.4494e-01, -6.3616e-01, -5.1597e-01,  2.1574e+00,\n",
      "          2.8825e-01,  2.2572e-01, -9.7179e-01, -7.5433e-01, -1.3276e-01,\n",
      "          4.8928e-02, -1.3791e+00,  1.9060e-01, -1.0415e+00, -6.3420e-01,\n",
      "         -8.3158e-01, -9.6967e-02,  1.0118e+00,  4.3609e-01,  4.6757e-01,\n",
      "         -1.2281e-01,  6.8141e-01,  4.3602e-01, -9.0663e-02, -3.7942e-01,\n",
      "         -4.3668e-01, -4.5740e-01, -3.7599e-01, -5.7632e-01,  1.1345e-01,\n",
      "         -1.7867e+00,  1.1908e-01, -8.4322e-02, -2.5107e-01,  5.9714e-01,\n",
      "         -3.4063e-01, -3.4361e-01, -1.5082e-01, -5.7989e-01, -7.9056e-02,\n",
      "         -7.1118e-01,  3.5589e-03,  1.2856e-01,  1.0480e+00, -3.5306e-01,\n",
      "         -3.7980e-01, -5.3804e-01, -5.8976e-01, -4.9803e-01,  2.6539e-01,\n",
      "          9.3087e-01,  1.0034e+00, -6.5383e-02,  3.8672e-01,  1.2677e+00,\n",
      "          3.5451e-01, -1.2184e+00, -2.2654e-01, -7.5529e-01,  4.2641e-01,\n",
      "          1.3579e+00,  3.2172e-01, -5.6564e-01,  3.0768e-01,  1.6686e+00,\n",
      "          1.3896e+00, -1.2565e+00,  2.2870e-01,  1.2295e+00, -5.0728e-01,\n",
      "          6.7308e-01,  7.5250e-01, -5.3082e-01,  4.2679e-01, -6.0367e-01,\n",
      "         -5.4101e-02, -3.1752e-01, -1.4701e+00,  1.6440e-01,  1.8439e-01,\n",
      "         -7.5211e-01,  7.1648e-01,  5.6180e-01, -3.8971e-01, -2.1763e-02,\n",
      "         -2.6344e-01,  4.3540e-01,  5.9147e-01,  5.4556e-01, -1.0154e+00,\n",
      "         -9.6374e-01,  7.6213e-01, -7.6375e-01]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings: {embeddings}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
