{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification\n",
    "- ref: https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "\n",
    "- dataset: [GonzaloA/fake_news](https://huggingface.co/datasets/GonzaloA/fake_news)\n",
    "- pretrained model: [distilbert/distilbert-base-uncased](https://huggingface.co/distilbert/distilbert-base-uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlefish/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "use the [`GonzaloA/fake_news`](https://huggingface.co/datasets/GonzaloA/fake_news) dataset from huggingface datasets library\n",
    "\n",
    "- 0: fake news\n",
    "- 1: real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Generating train split: 100%|██████████| 24353/24353 [00:00<00:00, 34987.88 examples/s]\n",
      "Generating validation split: 100%|██████████| 8117/8117 [00:00<00:00, 28487.49 examples/s]\n",
      "Generating test split: 100%|██████████| 8117/8117 [00:00<00:00, 40813.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset = load_dataset(\"GonzaloA/fake_news\", download_mode=\"reuse_cache_if_exists\", cache_dir=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 24353\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "print(f\"Dataset: {dataset}\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training sample\n",
      "Keys: dict_keys(['Unnamed: 0', 'title', 'text', 'label'])\n",
      "Title:  ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)\n",
      "Text: Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook \n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# quick look at the data\n",
    "first_train = train_dataset[0]\n",
    "print(f\"First training sample\")\n",
    "print(f\"Keys: {first_train.keys()}\")\n",
    "print(f\"Title: {first_train['title']}\")\n",
    "print(f\"Text: {first_train['text']}\")\n",
    "print(f\"Label: {first_train['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (Tokenize)\n",
    "The next step is to load a [`DistilBERT`](https://huggingface.co/distilbert/distilbert-base-uncased) tokenizer to preprocess the `text` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlefish/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERT’s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, use Datasets map function. \n",
    "\n",
    "You can speed up map by setting `batched=True` to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/24353 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24353/24353 [00:13<00:00, 1751.55 examples/s]\n",
      "Map: 100%|██████████| 8117/8117 [00:04<00:00, 1736.66 examples/s]\n",
      "Map: 100%|██████████| 8117/8117 [00:04<00:00, 1634.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, the dataset will contain the original text and the following attributes that DistilBERT uses as input:\n",
    "\n",
    "- `input_ids`: The token indices in the vocabulary\n",
    "- `attention_mask`: Which parts of the sequence DistilBERT should pay attention to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First tokenized sample\n",
      "Keys: dict_keys(['Unnamed: 0', 'title', 'text', 'label', 'input_ids', 'attention_mask'])\n",
      "Input IDs: [101, 5003, 13098, 2003, 3383, 2028, 1997, 1996, 11669, 10458, 3065, 2006, 2547, 2651, 1012, 2009, 1055, 2157, 1999, 2240, 2007, 1996, 7777, 1997, 1996, 9535, 3334, 11669, 2008, 2003, 6128, 17481, 1010, 1998, 1996, 2755, 2008, 2216, 3065, 2024, 2145, 2006, 1996, 2250, 2007, 1996, 4485, 2027, 2250, 2428, 2003, 1037, 6517, 9025, 2000, 2054, 4841, 2424, 2000, 2022, 14036, 1012, 2174, 1010, 5003, 13098, 2428, 4625, 1996, 2240, 2007, 1037, 9130, 2695, 4953, 2028, 1997, 2037, 4113, 1055, 3311, 2007, 1037, 25047, 1010, 19424, 14408, 3258, 2006, 9857, 3944, 1012, 2045, 2001, 1037, 2402, 2450, 2006, 2045, 2725, 2028, 1997, 2037, 4178, 4953, 1996, 6986, 11795, 3012, 1997, 2014, 2775, 1012, 2174, 1010, 2006, 1996, 3931, 1010, 1996, 2265, 6866, 2019, 3746, 1997, 1996, 2450, 1010, 2040, 6433, 2000, 4562, 1037, 8478, 14062, 2000, 5205, 1998, 4883, 4018, 6945, 8096, 1012, 1996, 14408, 3258, 2013, 1996, 5003, 13098, 2265, 3931, 3191, 1024, 1996, 4682, 19034, 3231, 4340, 1012, 2008, 2001, 1037, 4682, 999, 6945, 8096, 2003, 2074, 2025, 2008, 7916, 999, 2004, 2065, 2008, 4694, 1056, 9202, 2438, 1010, 1996, 14408, 3258, 7650, 1996, 10047, 27390, 2039, 11066, 9631, 1010, 6945, 8096, 1999, 8011, 2006, 5003, 13098, 1012, 2182, 2003, 2019, 3746, 2013, 1996, 2880, 5003, 13098, 9130, 3931, 1024, 2182, 2003, 1996, 7861, 8270, 1997, 1996, 2695, 2993, 1024, 2023, 2003, 3458, 4078, 24330, 3085, 1012, 2009, 1055, 2919, 2438, 2008, 2023, 2265, 8336, 2015, 2006, 7143, 2111, 2000, 2562, 2037, 11669, 2100, 2265, 2183, 1998, 2037, 4378, 1997, 3953, 1011, 21429, 2015, 21474, 1010, 2021, 2085, 2027, 7271, 12934, 2068, 2004, 2092, 1029, 2023, 2402, 2450, 3685, 2393, 2129, 2016, 3504, 2030, 2040, 2016, 12950, 1012, 2008, 2003, 2025, 2014, 6346, 1012, 25850, 2075, 2619, 1055, 3504, 2006, 2591, 2865, 2003, 2242, 2057, 1040, 5987, 2013, 1996, 22822, 5644, 2040, 3422, 2023, 10231, 2006, 1037, 3679, 3978, 1010, 2021, 2009, 2003, 2025, 2242, 1996, 2880, 2265, 3931, 2323, 2022, 2725, 1012, 2059, 2153, 1010, 2054, 2064, 2017, 5987, 2013, 1037, 2265, 2008, 9372, 1999, 1996, 8494, 2005, 1037, 2542, 1998, 4247, 2000, 2265, 1996, 2088, 2008, 2045, 2003, 2085, 2659, 2027, 2097, 2025, 2358, 18589, 2000, 1029, 2023, 2001, 2062, 2084, 1037, 3357, 2205, 2521, 1010, 2295, 1012, 5003, 13098, 1010, 2017, 12533, 2023, 2402, 2450, 1037, 2270, 12480, 1012, 1037, 2200, 2270, 12480, 1012, 2045, 1055, 2074, 2053, 8016, 2005, 2023, 1010, 2053, 3043, 1996, 28321, 1997, 2115, 4378, 2030, 2054, 2017, 2079, 2006, 2008, 19424, 2265, 1997, 6737, 1012, 1045, 6814, 2009, 2097, 2022, 2205, 2172, 2000, 3198, 2008, 2017, 4558, 7193, 2058, 2023, 1010, 2138, 1996, 2111, 2040, 3422, 2115, 11669, 2100, 4632, 2265, 3497, 4995, 1056, 5161, 2438, 2000, 3305, 2339, 2023, 2003, 2061, 3308, 1999, 1996, 2034, 2173, 1012, 1045, 2123, 1056, 3422, 1010, 2061, 1045, 2064, 1056, 2139, 18098, 3512, 2017, 1997, 2026, 7193, 5605, 1010, 2021, 1045, 2064, 2655, 2017, 2041, 1012, 9467, 2006, 2017, 1010, 5003, 13098, 2265, 1998, 3071, 3378, 2007, 2023, 4078, 24330, 3085, 9130, 2695, 1012, 2017, 2428, 3662, 2115, 2995, 6087, 2182, 2651, 1012, 2956, 102]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Length: 512\n"
     ]
    }
   ],
   "source": [
    "# tokenized\n",
    "first_tokenized = tokenized_dataset[\"train\"][0]\n",
    "print(f\"First tokenized sample\")\n",
    "print(f\"Keys: {first_tokenized.keys()}\")\n",
    "print(f\"Input IDs: {first_tokenized['input_ids']}\")\n",
    "print(f\"Attention Mask: {first_tokenized['attention_mask']}\")\n",
    "print(f\"Length: {len(first_tokenized['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric (see the 🤗 Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "# precision = evaluate.load(\"precision\")\n",
    "# recall = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    # pre = precision.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    # rec = recall.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    results = {\"accuracy\": acc['accuracy'], \"f1\": f1_score['f1']}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Finetune the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"fake\", 1: \"real\"}\n",
    "label2id = {\"fake\": 0, \"real\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
    "\n",
    "</Tip>\n",
    "\n",
    "You're ready to start training your model now! \n",
    "\n",
    "Load DistilBERT with [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification) along with the number of expected labels, and the label mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, only three steps remain:\n",
    "\n",
    "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the accuracy and save the training checkpoint.\n",
    "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n",
    "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "output_dir = \"checkpoints/sample\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tip>\n",
    "\n",
    "[Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) applies dynamic padding by default when you pass `tokenizer` to it. In this case, you don't need to specify a data collator explicitly.\n",
    "\n",
    "</Tip>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "trainer.save_model(f\"{output_dir}/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics (on testing dataset)\n",
    "- Accuracy\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlefish/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/littlefish/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "# evaluate on validation set\n",
    "val_result = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.027922283858060837,\n",
       " 'eval_accuracy': 0.9859554022422077,\n",
       " 'eval_f1': 0.9859627860717326,\n",
       " 'eval_runtime': 34.459,\n",
       " 'eval_samples_per_second': 235.555,\n",
       " 'eval_steps_per_second': 1.857,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "val_df = pd.DataFrame(val_result, index=[0])\n",
    "val_df.to_csv(f\"{output_dir}/val_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "test_result = trainer.evaluate(eval_dataset=tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.029379427433013916,\n",
       " 'eval_accuracy': 0.986694591597881,\n",
       " 'eval_f1': 0.9866952574111764,\n",
       " 'eval_runtime': 34.4597,\n",
       " 'eval_samples_per_second': 235.55,\n",
       " 'eval_steps_per_second': 1.857,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eval_loss  eval_accuracy   eval_f1  eval_runtime  eval_samples_per_second  \\\n",
      "0   0.029379       0.986695  0.986695       34.4597                   235.55   \n",
      "\n",
      "   eval_steps_per_second  epoch  \n",
      "0                  1.857    1.0  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_result, index=[0])\n",
    "test_df.to_csv(f\"{output_dir}/test_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that you've finetuned a model, you can use it for inference!\n",
    "\n",
    "Grab some text you'd like to run inference on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: JOE DIGENOVA has been around D.C for decades and has seen it all. He probably didn t see his one coming. The incoming president  was set-up to be taken down. A soft coup is in the works and DiGenova has this to say about it:\"It's very clear that they conspired to frame the incoming President of the United States.\"  Joe diGenova on allegations of anti-Trump bias at FBI and TheJusticeDept #Tucker https://t.co/qUNjAenzJc pic.twitter.com/VDlhb45Ghi  G. Ashley Hawkins (@g_ashleyhawkins) December 16, 2017DiGenova on Tucker Carlson tonight: Inside the FBI and Department of Justice under Obama was a brazen plot to do two things. To exonerate Hillary Clinton because of an animous for Donald Trump, and then if she lost to frame the incoming president for either a criminal act or impeachment. This is one of the most disgusting performances by the senior officials at the FBI and the Department of Justice that everyone of these agents should be fired and the people who are still in the Justice Department be fired including Mr. Ohr and they impanel a federal grand jury to investigate the conduct of McCabe and Strzok and Page and Comey and Ohr and everybody in the Obama Justice Department that even touched this. It s very clear that they conspired to frame the incoming president of the United States.DIGENOVA S WIFE VICTORIA TOENSING IS REPRESENTING A FORMER FBI INFORMANT WHO HAS THE GOODS ON THE URANIUM ONE DEAL: DC lawyer Victoria Toensing is one smart cookie. She s representing a former FBI informant who has evidence on kickbacks and bribery involving the transportation of uranium in the US. She recently told Sean Hannity her client will brief Congress about Russian involvement in the U.S. uranium market. This includes widespread bribery and actions that involved the Clintons https://www.youtube.com/watch?v=eDVndQRW22Q I m not going into detail,  attorney Victoria Toensing said on the Oct. 24 Hannity.  You know that, Sean. But the informant will give an overview and specific conversations that he had with Russians in what they were thinking about the money that they were spending. I mean, let me just be that general and it involves the Clintons. The director of the FBI at that time was Robert Mueller, and he is now the special counsel investigating alleged Russian collusion with the 2016 Trump campaign. The undercover investigation involving Toensing s client occurred between 2009 and 2014, and the senior attorney on the case was Rod Rosenstein, who is now the deputy attorney general of the United States and the official who appointed Mueller as special counsel.Further, all this information indicates that many senior Obama administration officials knew about instances of bribery and money laundering involving at least one Russian official, at a time when Russia wanted to expand its uranium market in the United States, and when the administration through a special committee had to approve or deny the sale of a company, Vancouver-based Uranium One, to Rosatom. (Rosatom is the Russian State Atomic Energy Corporation.)Some of the people on that Committee on Foreign Investment in the United States included then-Secretary of State Hillary Clinton, Attorney General Eric Holder, Homeland Security Secretary Janet Napalitano, and Treasury Secretary Timothy Geithner.The committee approved the sale of Uranium One to Rosatom in October 2010. That sale gave Russia, and President Vladimir Putin, control over 20% of U.S. uranium production. (At least nine investors in Uranium One   prior to, during, and after that sale   donated $145 million to the Clinton Foundation.) So, Mueller, [Rod] Rosenstein, maybe even [James] Comey at the time, and the president of the United States   certainly Eric Holder was the head of the DOJ   they all knew that they had all this evidence that the Russians had infiltrated with the purpose of a criminal enterprise to corner the market on uranium, the foundational material of nuclear weapons?  asked Hannity.Toensing said,  That is correct. Via: cns news\n"
     ]
    }
   ],
   "source": [
    "text = test_dataset[0][\"text\"]\n",
    "print(f\"Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'fake', 'score': 0.9989815354347229}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=f\"{output_dir}/best_model\", truncation=True, device=device)\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually replicate the results of the `pipeline` if you'd like:\n",
    "\n",
    "Tokenize the text and return PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input keys: dict_keys(['input_ids', 'attention_mask'])\n",
      "Input: {'input_ids': tensor([[  101,  3533, 10667, 16515,  3567,  2038,  2042,  2105,  1040,  1012,\n",
      "          1039,  2005,  5109,  1998,  2038,  2464,  2009,  2035,  1012,  2002,\n",
      "          2763,  2134,  1056,  2156,  2010,  2028,  2746,  1012,  1996, 14932,\n",
      "          2343,  2001,  2275,  1011,  2039,  2000,  2022,  2579,  2091,  1012,\n",
      "          1037,  3730,  8648,  2003,  1999,  1996,  2573,  1998, 10667, 16515,\n",
      "          3567,  2038,  2023,  2000,  2360,  2055,  2009,  1024,  1000,  2009,\n",
      "          1005,  1055,  2200,  3154,  2008,  2027,  9530, 13102, 27559,  2000,\n",
      "          4853,  1996, 14932,  2343,  1997,  1996,  2142,  2163,  1012,  1000,\n",
      "          3533, 10667, 16515,  3567,  2006,  9989,  1997,  3424,  1011,  8398,\n",
      "         13827,  2012,  8495,  1998,  1996, 29427,  6610,  3207, 13876,  1001,\n",
      "          9802, 16770,  1024,  1013,  1013,  1056,  1012,  2522,  1013, 24209,\n",
      "          2078,  3900,  2368,  2480,  3501,  2278, 27263,  1012, 10474,  1012,\n",
      "          4012,  1013,  1058, 19422,  2232,  2497, 19961, 28891,  1043,  1012,\n",
      "          9321, 13835,  1006,  1030,  1043,  1035,  9321, 17998,  7076,  1007,\n",
      "          2285,  2385,  1010,  2418,  4305,  6914,  7103,  2006,  9802, 22226,\n",
      "          3892,  1024,  2503,  1996,  8495,  1998,  2533,  1997,  3425,  2104,\n",
      "          8112,  2001,  1037, 11655, 10431,  5436,  2000,  2079,  2048,  2477,\n",
      "          1012,  2000,  4654,  5643, 11657, 18520,  7207,  2138,  1997,  2019,\n",
      "          2019, 16339,  2271,  2005,  6221,  8398,  1010,  1998,  2059,  2065,\n",
      "          2016,  2439,  2000,  4853,  1996, 14932,  2343,  2005,  2593,  1037,\n",
      "          4735,  2552,  2030, 17727,  5243, 22729,  1012,  2023,  2003,  2028,\n",
      "          1997,  1996,  2087, 19424,  4616,  2011,  1996,  3026,  4584,  2012,\n",
      "          1996,  8495,  1998,  1996,  2533,  1997,  3425,  2008,  3071,  1997,\n",
      "          2122,  6074,  2323,  2022,  5045,  1998,  1996,  2111,  2040,  2024,\n",
      "          2145,  1999,  1996,  3425,  2533,  2022,  5045,  2164,  2720,  1012,\n",
      "          2821,  2099,  1998,  2027, 17727,  7231,  2140,  1037,  2976,  2882,\n",
      "          6467,  2000,  8556,  1996,  6204,  1997, 23680, 16336,  1998,  2358,\n",
      "         15378,  6559,  1998,  3931,  1998,  2272,  2100,  1998,  2821,  2099,\n",
      "          1998,  7955,  1999,  1996,  8112,  3425,  2533,  2008,  2130,  5028,\n",
      "          2023,  1012,  2009,  1055,  2200,  3154,  2008,  2027,  9530, 13102,\n",
      "         27559,  2000,  4853,  1996, 14932,  2343,  1997,  1996,  2142,  2163,\n",
      "          1012, 10667, 16515,  3567,  1055,  2564,  3848, 11756,  3619,  2075,\n",
      "          2003,  5052,  1037,  2280,  8495, 28694,  2040,  2038,  1996,  5350,\n",
      "          2006,  1996, 14247,  2028,  3066,  1024,  5887,  5160,  3848, 11756,\n",
      "          3619,  2075,  2003,  2028,  6047, 17387,  1012,  2016,  1055,  5052,\n",
      "          1037,  2280,  8495, 28694,  2040,  2038,  3350,  2006,  5926, 12221,\n",
      "          1998, 27748,  5994,  1996,  5193,  1997, 14247,  1999,  1996,  2149,\n",
      "          1012,  2016,  3728,  2409,  5977,  7658, 22758,  2014,  7396,  2097,\n",
      "          4766,  3519,  2055,  2845,  6624,  1999,  1996,  1057,  1012,  1055,\n",
      "          1012, 14247,  3006,  1012,  2023,  2950,  6923, 27748,  1998,  4506,\n",
      "          2008,  2920,  1996,  7207,  2015, 16770,  1024,  1013,  1013,  7479,\n",
      "          1012,  7858,  1012,  4012,  1013,  3422,  1029,  1058,  1027,  3968,\n",
      "         16022,  2094,  4160,  2099,  2860, 19317,  4160,  1045,  1049,  2025,\n",
      "          2183,  2046,  6987,  1010,  4905,  3848, 11756,  3619,  2075,  2056,\n",
      "          2006,  1996, 13323,  1012,  2484,  7658, 22758,  1012,  2017,  2113,\n",
      "          2008,  1010,  5977,  1012,  2021,  1996, 28694,  2097,  2507,  2019,\n",
      "         19184,  1998,  3563, 11450,  2008,  2002,  2018,  2007, 12513,  1999,\n",
      "          2054,  2027,  2020,  3241,  2055,  1996,  2769,  2008,  2027,  2020,\n",
      "          5938,  1012,  1045,  2812,  1010,  2292,  2033,  2074,  2022,  2008,\n",
      "          2236,  1998,  2009,  7336,  1996,  7207,  2015,  1012,  1996,  2472,\n",
      "          1997,  1996,  8495,  2012,  2008,  2051,  2001,  2728, 26774,  1010,\n",
      "          1998,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"{output_dir}/best_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "print(f\"Input keys: {inputs.keys()}\")\n",
    "print(f\"Input: {inputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass your inputs to the model and return the `logits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ 3.1090, -3.7794]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"{output_dir}/best_model\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "print(f\"Logits: {logits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the class with the highest probability, and use the model's `id2label` mapping to convert it to a text label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forgery-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
